{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#import glob\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import densenet121, vgg16, resnet50, inception_v3\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from common.myfunctions import plot_confusion_matrix\n",
    "from common.customloss import QuadraticKappa, WeightedMultiLabelLogLoss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/srv/app/data'\n",
    "\n",
    "DATA_DIR = BASE_DIR + '/data'\n",
    "\n",
    "MODEL_DIR = BASE_DIR + '/models'\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + '/numpy_array/stage_1_train_images_299'\n",
    "TEST_DIR = DATA_DIR + '/numpy_array/stage_1_train_images_299' #Same path because we split train in train and test.\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR + '/stage_1_train_pivoted.csv'\n",
    "TEST_LABELS = DATA_DIR + ''\n",
    "\n",
    "BATCH_SIZE = 224\n",
    "\n",
    "NUM_EPOCH = 30\n",
    "\n",
    "TEST_SPLIT = 0.3\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "LABEL_COLUMN = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "INPUT_SIZE = 299\n",
    "\n",
    "IMAGE_FORMAT = 'npy'\n",
    "\n",
    "MODELS = ['FineTuningResNet50']\n",
    "\n",
    "OPTIMIZERS = ['DefaultAdam']\n",
    "\n",
    "LOSSES = ['WeightedMultiLabelLogLoss']\n",
    "\n",
    "SAMPLE_FRAC = 0.5 #Fraction of dataset to use. Set to 1.0 to use the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = {\n",
    "    'PreDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3', \n",
    "                             'denseblock4', 'norm5']\n",
    "    },\n",
    "    'FineTuningDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningDensenet121v1': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3']\n",
    "    },\n",
    "    'FineTuningDensenet121v2': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningDensenet121v1',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2']\n",
    "    },\n",
    "    'PreVGG16': {\n",
    "        'base_model': 'vgg16',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['features.0', 'features.2', 'features.5', 'features.7', \n",
    "                             'features.10', 'features.12', 'features.14', 'features.17', \n",
    "                             'features.19', 'features.21', 'features.24', 'features.26', \n",
    "                             'features.28', 'classifier.0', 'classifier.3']\n",
    "    },\n",
    "    'PreResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "    },\n",
    "    'FineTuningResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50v1': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "    },\n",
    "    'FineTuningResNet50v2': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningResNet50v1',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "    },\n",
    "    'PreInceptionV3': {\n",
    "        'base_model': 'inception_v3',\n",
    "        'is_inception': True,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['AuxLogits.conv0', 'AuxLogits.conv1', 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', \n",
    "                             'Conv2d_2b_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', \n",
    "                             'Mixed_5b.branch1x1', 'Mixed_5b.branch3x3dbl_1', \n",
    "                             'Mixed_5b.branch3x3dbl_2', 'Mixed_5b.branch3x3dbl_3', 'Mixed_5b.branch5x5_1', \n",
    "                             'Mixed_5b.branch5x5_2', 'Mixed_5b.branch_pool', 'Mixed_5c.branch1x1', \n",
    "                             'Mixed_5c.branch3x3dbl_1', 'Mixed_5c.branch3x3dbl_2', 'Mixed_5c.branch3x3dbl_3', \n",
    "                             'Mixed_5c.branch5x5_1', 'Mixed_5c.branch5x5_2', 'Mixed_5c.branch_pool', \n",
    "                             'Mixed_5d.branch1x1', 'Mixed_5d.branch3x3dbl_1', 'Mixed_5d.branch3x3dbl_2', \n",
    "                             'Mixed_5d.branch3x3dbl_3', 'Mixed_5d.branch5x5_1', 'Mixed_5d.branch5x5_2', \n",
    "                             'Mixed_5d.branch_pool', 'Mixed_6a.branch3x3', 'Mixed_6a.branch3x3dbl_1', \n",
    "                             'Mixed_6a.branch3x3dbl_2', 'Mixed_6a.branch3x3dbl_3', 'Mixed_6b.branch1x1', \n",
    "                             'Mixed_6b.branch7x7_1', 'Mixed_6b.branch7x7_2', 'Mixed_6b.branch7x7_3', \n",
    "                             'Mixed_6b.branch7x7dbl_1', 'Mixed_6b.branch7x7dbl_2', 'Mixed_6b.branch7x7dbl_3', \n",
    "                             'Mixed_6b.branch7x7dbl_4', 'Mixed_6b.branch7x7dbl_5', 'Mixed_6b.branch_pool', \n",
    "                             'Mixed_6c.branch1x1', 'Mixed_6c.branch7x7_1', 'Mixed_6c.branch7x7_2', \n",
    "                             'Mixed_6c.branch7x7_3', 'Mixed_6c.branch7x7dbl_1', 'Mixed_6c.branch7x7dbl_2', \n",
    "                             'Mixed_6c.branch7x7dbl_3', 'Mixed_6c.branch7x7dbl_4', 'Mixed_6c.branch7x7dbl_5', \n",
    "                             'Mixed_6c.branch_pool', 'Mixed_6d.branch1x1', 'Mixed_6d.branch7x7_1', \n",
    "                             'Mixed_6d.branch7x7_2', 'Mixed_6d.branch7x7_3', 'Mixed_6d.branch7x7dbl_1', \n",
    "                             'Mixed_6d.branch7x7dbl_2', 'Mixed_6d.branch7x7dbl_3', 'Mixed_6d.branch7x7dbl_4', \n",
    "                             'Mixed_6d.branch7x7dbl_5', 'Mixed_6d.branch_pool', 'Mixed_6e.branch1x1', \n",
    "                             'Mixed_6e.branch7x7_1', 'Mixed_6e.branch7x7_2', 'Mixed_6e.branch7x7_3', \n",
    "                             'Mixed_6e.branch7x7dbl_1', 'Mixed_6e.branch7x7dbl_2', 'Mixed_6e.branch7x7dbl_3', \n",
    "                             'Mixed_6e.branch7x7dbl_4', 'Mixed_6e.branch7x7dbl_5', 'Mixed_6e.branch_pool', \n",
    "                             'Mixed_7a.branch3x3_1', 'Mixed_7a.branch3x3_2', 'Mixed_7a.branch7x7x3_1', \n",
    "                             'Mixed_7a.branch7x7x3_2', 'Mixed_7a.branch7x7x3_3', 'Mixed_7a.branch7x7x3_4', \n",
    "                             'Mixed_7b.branch1x1', 'Mixed_7b.branch3x3_1', 'Mixed_7b.branch3x3_2a', \n",
    "                             'Mixed_7b.branch3x3_2b', 'Mixed_7b.branch3x3dbl_1', 'Mixed_7b.branch3x3dbl_2', \n",
    "                             'Mixed_7b.branch3x3dbl_3a', 'Mixed_7b.branch3x3dbl_3b', 'Mixed_7b.branch_pool', \n",
    "                             'Mixed_7c.branch1x1', 'Mixed_7c.branch3x3_1', 'Mixed_7c.branch3x3_2a', \n",
    "                             'Mixed_7c.branch3x3_2b', 'Mixed_7c.branch3x3dbl_1', 'Mixed_7c.branch3x3dbl_2', \n",
    "                             'Mixed_7c.branch3x3dbl_3a', 'Mixed_7c.branch3x3dbl_3b', 'Mixed_7c.branch_pool']\n",
    "    },\n",
    "    'PreEfficientNetB7': {\n",
    "        'base_model': 'efficientnetb7',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['_conv_stem', '_bn0', '_blocks', '_conv_head', '_bn1']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER_LIST = {\n",
    "    'DefaultAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.001,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0,\n",
    "        'amsgrad': False\n",
    "    }\n",
    "}\n",
    "\n",
    "LOSS_LIST = {\n",
    "    'DefaultNLLLoss': {\n",
    "        'function': 'NLLLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultSmoothL1Loss': {\n",
    "        'function': 'SmoothL1Loss',\n",
    "        'size_average': None,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultCrossEntropyLoss': {\n",
    "        'function': 'CrossEntropyLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'QuadraticKappa': {\n",
    "        'function': 'QuadraticKappa',\n",
    "        'n_classes': NUM_CLASSES\n",
    "    },\n",
    "    'WeightedMultiLabelLogLoss': {\n",
    "        'function': 'WeightedMultiLabelLogLoss',\n",
    "        'n_classes': NUM_CLASSES,\n",
    "        'weight': None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)    \n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, img_folder, img_ext='png', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (dataframe): Dataframe with images ID.\n",
    "            y (dataframe): Dataframe with labels annotations.\n",
    "            img_folder (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.img_folder = img_folder\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "        self.hu_min = -1024 # Min value of Hounsfield scale\n",
    "        self.hu_max = 3071 # Max value of Hounsfield scale\n",
    "        self.hu_delta = self.hu_max - self.hu_min # Just to save calculation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "        #image = np.load(img_name).astype('uint8')\n",
    "        image = np.load(img_name)\n",
    "        \n",
    "        label = self.y.iloc[idx].to_numpy()\n",
    "        \n",
    "        if self.transform:\n",
    "        \n",
    "            image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "        return (image,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN_LABELS)\n",
    "\n",
    "################ Esta faltando apenas essa imagem no dataset ################\n",
    "data = data.loc[data.id != 'ID_6431af929']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fad60bc5550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    data = data.sample(frac = SAMPLE_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fad5972b470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39598799, 13.9259125 ,  1.16698064,  1.62317922,  1.20445518,\n",
       "        0.90940159])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distrib_freq = data[LABEL_COLUMN].sum().to_numpy()\n",
    "w_classes = distrib_freq.sum() / (NUM_CLASSES * distrib_freq)\n",
    "w_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Wrong Loss Function Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in LOSSES:\n",
    "    if 'weight' in LOSS_LIST[l]:\n",
    "        LOSS_LIST[l]['weight'] = torch.from_numpy(w_classes).to(device)\n",
    "    else:\n",
    "        raise Exception('You are trying to set weight in a loss function without weight parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(LABEL_COLUMN, axis=1)\n",
    "y = data[LABEL_COLUMN]\n",
    "\n",
    "# Criando o dataframe de treine e teste com base no dataframe anteriormente criado\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = TEST_SPLIT, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf = transforms.Compose([\n",
    "    transforms.RandomRotation((0,360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X=X_train, \n",
    "                              y=y_train, \n",
    "                              img_folder=TRAIN_DIR,\n",
    "                              img_ext=IMAGE_FORMAT, \n",
    "                              transform=train_transf)\n",
    "\n",
    "test_dataset = CustomDataset(X=X_test, \n",
    "                             y=y_test, \n",
    "                             img_folder=TEST_DIR, \n",
    "                             img_ext=IMAGE_FORMAT,\n",
    "                             transform=test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garregando os dados\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBestModel(model_name):\n",
    "    # Get lastest model file\n",
    "    list_of_files = glob.glob(MODEL_DIR + f'/*{model_name}*.pt') # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f'Loading model {latest_file}')\n",
    "    model = torch.load(latest_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name, num_classes):\n",
    "    \n",
    "    model_parameters = MODEL_LIST[model_name]\n",
    "    \n",
    "    if model_parameters['load_checkpoint']:\n",
    "        \n",
    "        model = loadBestModel(model_parameters['checkpoint_from'])\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        if model_parameters['base_model']=='densenet121':\n",
    "            \n",
    "            model = densenet121(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier = nn.Linear(1024, num_classes)   \n",
    "            \n",
    "        if model_parameters['base_model']=='vgg16':\n",
    "            \n",
    "            model = vgg16(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier[6] = nn.Linear(4096, num_classes) \n",
    "        \n",
    "        if model_parameters['base_model']=='resnet50':\n",
    "            \n",
    "            model = resnet50(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    "            \n",
    "        if model_parameters['base_model']=='inception_v3':\n",
    "            \n",
    "            model = inception_v3(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    "            model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            \n",
    "        elif model_parameters['base_model']=='efficientnetb7':\n",
    "            \n",
    "            model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "            model._fc = nn.Linear(2560, NUM_CLASSES) \n",
    "            \n",
    "        if (torch.cuda.device_count() > 1) & (not model_parameters['is_inception']):\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            model = nn.DataParallel(model) # When load checkpoint, the DataParallel is already in the model.\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        for l in model_parameters['layers_to_frozen']:\n",
    "            if l in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    if is_cuda:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizer(optimizer_name, model):\n",
    "\n",
    "    params_to_update = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "    \n",
    "        if param.requires_grad == True:\n",
    "        \n",
    "            params_to_update.append(param)\n",
    "            \n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    opt_parameters = OPTIMIZER_LIST[optimizer_name]\n",
    "\n",
    "    if opt_parameters['function'] == 'Adam':\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params_to_update, \n",
    "                                     lr = opt_parameters['lr'],\n",
    "                                     betas = opt_parameters['betas'],\n",
    "                                     eps = opt_parameters['eps'],\n",
    "                                     weight_decay = opt_parameters['weight_decay'],\n",
    "                                     amsgrad = opt_parameters['amsgrad']\n",
    "                                    )\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossFunction(loss_nme):\n",
    "    \n",
    "    loss_parameters = LOSS_LIST[loss_nme]\n",
    "\n",
    "    if loss_parameters['function'] == 'SmoothL1Loss':\n",
    "        criterion = nn.SmoothL1Loss(\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'CrossEntropyLoss':\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'NLLLoss':\n",
    "\n",
    "        criterion = nn.NLLLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'QuadraticKappa':\n",
    "        criterion = QuadraticKappa(\n",
    "            n_classes = loss_parameters['n_classes']\n",
    "        )\n",
    "        \n",
    "    elif loss_parameters['function'] == 'WeightedMultiLabelLogLoss':\n",
    "\n",
    "        criterion = WeightedMultiLabelLogLoss(\n",
    "            n_classes = loss_parameters['n_classes'],\n",
    "            weight = loss_parameters['weight']\n",
    "        )\n",
    "        \n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def onehot(labels, num_classes):\n",
    "    return torch.zeros(len(labels), num_classes).scatter_(1, labels.unsqueeze(1).cpu(), 1.).cuda()\n",
    "\n",
    "def train_model(model, model_name, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_loss = 999\n",
    "    \n",
    "    print(model_name)\n",
    "    print('-' * 100)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        epoch_since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            #running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        \n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        aux_outputs = torch.sigmoid(aux_outputs)\n",
    "                        \n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        outputs = model(inputs)\n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            #epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            #lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # Write loss into Tensorboard\n",
    "            tensorboard.add_scalar('Loss {}'.format(phase), epoch_loss, epoch)\n",
    "            #tensorboard.add_scalar('Acc {}'.format(phase), epoch_acc, epoch)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Saving the best model...')\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model, MODEL_DIR + '/' + model_name + '_imgsize' + str(INPUT_SIZE) + '_loss' + str(best_loss) + '.pt')\n",
    "            \n",
    "        epoch_time_elapsed = time.time() - epoch_since\n",
    "        print('Epoch time elapsed: {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('')\n",
    "\n",
    "    # load best model weights\n",
    "    model = loadBestModel(model_name)\n",
    "    return model, best_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model /srv/app/data/models/FineTuningResNet50_DefaultAdam_WeightedMultiLabelLogLoss_imgsize299_loss0.15992117286916552.pt\n",
      "\t module.conv1.weight\n",
      "\t module.bn1.weight\n",
      "\t module.bn1.bias\n",
      "\t module.layer1.0.conv1.weight\n",
      "\t module.layer1.0.bn1.weight\n",
      "\t module.layer1.0.bn1.bias\n",
      "\t module.layer1.0.conv2.weight\n",
      "\t module.layer1.0.bn2.weight\n",
      "\t module.layer1.0.bn2.bias\n",
      "\t module.layer1.0.conv3.weight\n",
      "\t module.layer1.0.bn3.weight\n",
      "\t module.layer1.0.bn3.bias\n",
      "\t module.layer1.0.downsample.0.weight\n",
      "\t module.layer1.0.downsample.1.weight\n",
      "\t module.layer1.0.downsample.1.bias\n",
      "\t module.layer1.1.conv1.weight\n",
      "\t module.layer1.1.bn1.weight\n",
      "\t module.layer1.1.bn1.bias\n",
      "\t module.layer1.1.conv2.weight\n",
      "\t module.layer1.1.bn2.weight\n",
      "\t module.layer1.1.bn2.bias\n",
      "\t module.layer1.1.conv3.weight\n",
      "\t module.layer1.1.bn3.weight\n",
      "\t module.layer1.1.bn3.bias\n",
      "\t module.layer1.2.conv1.weight\n",
      "\t module.layer1.2.bn1.weight\n",
      "\t module.layer1.2.bn1.bias\n",
      "\t module.layer1.2.conv2.weight\n",
      "\t module.layer1.2.bn2.weight\n",
      "\t module.layer1.2.bn2.bias\n",
      "\t module.layer1.2.conv3.weight\n",
      "\t module.layer1.2.bn3.weight\n",
      "\t module.layer1.2.bn3.bias\n",
      "\t module.layer2.0.conv1.weight\n",
      "\t module.layer2.0.bn1.weight\n",
      "\t module.layer2.0.bn1.bias\n",
      "\t module.layer2.0.conv2.weight\n",
      "\t module.layer2.0.bn2.weight\n",
      "\t module.layer2.0.bn2.bias\n",
      "\t module.layer2.0.conv3.weight\n",
      "\t module.layer2.0.bn3.weight\n",
      "\t module.layer2.0.bn3.bias\n",
      "\t module.layer2.0.downsample.0.weight\n",
      "\t module.layer2.0.downsample.1.weight\n",
      "\t module.layer2.0.downsample.1.bias\n",
      "\t module.layer2.1.conv1.weight\n",
      "\t module.layer2.1.bn1.weight\n",
      "\t module.layer2.1.bn1.bias\n",
      "\t module.layer2.1.conv2.weight\n",
      "\t module.layer2.1.bn2.weight\n",
      "\t module.layer2.1.bn2.bias\n",
      "\t module.layer2.1.conv3.weight\n",
      "\t module.layer2.1.bn3.weight\n",
      "\t module.layer2.1.bn3.bias\n",
      "\t module.layer2.2.conv1.weight\n",
      "\t module.layer2.2.bn1.weight\n",
      "\t module.layer2.2.bn1.bias\n",
      "\t module.layer2.2.conv2.weight\n",
      "\t module.layer2.2.bn2.weight\n",
      "\t module.layer2.2.bn2.bias\n",
      "\t module.layer2.2.conv3.weight\n",
      "\t module.layer2.2.bn3.weight\n",
      "\t module.layer2.2.bn3.bias\n",
      "\t module.layer2.3.conv1.weight\n",
      "\t module.layer2.3.bn1.weight\n",
      "\t module.layer2.3.bn1.bias\n",
      "\t module.layer2.3.conv2.weight\n",
      "\t module.layer2.3.bn2.weight\n",
      "\t module.layer2.3.bn2.bias\n",
      "\t module.layer2.3.conv3.weight\n",
      "\t module.layer2.3.bn3.weight\n",
      "\t module.layer2.3.bn3.bias\n",
      "\t module.layer3.0.conv1.weight\n",
      "\t module.layer3.0.bn1.weight\n",
      "\t module.layer3.0.bn1.bias\n",
      "\t module.layer3.0.conv2.weight\n",
      "\t module.layer3.0.bn2.weight\n",
      "\t module.layer3.0.bn2.bias\n",
      "\t module.layer3.0.conv3.weight\n",
      "\t module.layer3.0.bn3.weight\n",
      "\t module.layer3.0.bn3.bias\n",
      "\t module.layer3.0.downsample.0.weight\n",
      "\t module.layer3.0.downsample.1.weight\n",
      "\t module.layer3.0.downsample.1.bias\n",
      "\t module.layer3.1.conv1.weight\n",
      "\t module.layer3.1.bn1.weight\n",
      "\t module.layer3.1.bn1.bias\n",
      "\t module.layer3.1.conv2.weight\n",
      "\t module.layer3.1.bn2.weight\n",
      "\t module.layer3.1.bn2.bias\n",
      "\t module.layer3.1.conv3.weight\n",
      "\t module.layer3.1.bn3.weight\n",
      "\t module.layer3.1.bn3.bias\n",
      "\t module.layer3.2.conv1.weight\n",
      "\t module.layer3.2.bn1.weight\n",
      "\t module.layer3.2.bn1.bias\n",
      "\t module.layer3.2.conv2.weight\n",
      "\t module.layer3.2.bn2.weight\n",
      "\t module.layer3.2.bn2.bias\n",
      "\t module.layer3.2.conv3.weight\n",
      "\t module.layer3.2.bn3.weight\n",
      "\t module.layer3.2.bn3.bias\n",
      "\t module.layer3.3.conv1.weight\n",
      "\t module.layer3.3.bn1.weight\n",
      "\t module.layer3.3.bn1.bias\n",
      "\t module.layer3.3.conv2.weight\n",
      "\t module.layer3.3.bn2.weight\n",
      "\t module.layer3.3.bn2.bias\n",
      "\t module.layer3.3.conv3.weight\n",
      "\t module.layer3.3.bn3.weight\n",
      "\t module.layer3.3.bn3.bias\n",
      "\t module.layer3.4.conv1.weight\n",
      "\t module.layer3.4.bn1.weight\n",
      "\t module.layer3.4.bn1.bias\n",
      "\t module.layer3.4.conv2.weight\n",
      "\t module.layer3.4.bn2.weight\n",
      "\t module.layer3.4.bn2.bias\n",
      "\t module.layer3.4.conv3.weight\n",
      "\t module.layer3.4.bn3.weight\n",
      "\t module.layer3.4.bn3.bias\n",
      "\t module.layer3.5.conv1.weight\n",
      "\t module.layer3.5.bn1.weight\n",
      "\t module.layer3.5.bn1.bias\n",
      "\t module.layer3.5.conv2.weight\n",
      "\t module.layer3.5.bn2.weight\n",
      "\t module.layer3.5.bn2.bias\n",
      "\t module.layer3.5.conv3.weight\n",
      "\t module.layer3.5.bn3.weight\n",
      "\t module.layer3.5.bn3.bias\n",
      "\t module.layer4.0.conv1.weight\n",
      "\t module.layer4.0.bn1.weight\n",
      "\t module.layer4.0.bn1.bias\n",
      "\t module.layer4.0.conv2.weight\n",
      "\t module.layer4.0.bn2.weight\n",
      "\t module.layer4.0.bn2.bias\n",
      "\t module.layer4.0.conv3.weight\n",
      "\t module.layer4.0.bn3.weight\n",
      "\t module.layer4.0.bn3.bias\n",
      "\t module.layer4.0.downsample.0.weight\n",
      "\t module.layer4.0.downsample.1.weight\n",
      "\t module.layer4.0.downsample.1.bias\n",
      "\t module.layer4.1.conv1.weight\n",
      "\t module.layer4.1.bn1.weight\n",
      "\t module.layer4.1.bn1.bias\n",
      "\t module.layer4.1.conv2.weight\n",
      "\t module.layer4.1.bn2.weight\n",
      "\t module.layer4.1.bn2.bias\n",
      "\t module.layer4.1.conv3.weight\n",
      "\t module.layer4.1.bn3.weight\n",
      "\t module.layer4.1.bn3.bias\n",
      "\t module.layer4.2.conv1.weight\n",
      "\t module.layer4.2.bn1.weight\n",
      "\t module.layer4.2.bn1.bias\n",
      "\t module.layer4.2.conv2.weight\n",
      "\t module.layer4.2.bn2.weight\n",
      "\t module.layer4.2.bn2.bias\n",
      "\t module.layer4.2.conv3.weight\n",
      "\t module.layer4.2.bn3.weight\n",
      "\t module.layer4.2.bn3.bias\n",
      "\t module.fc.weight\n",
      "\t module.fc.bias\n",
      "FineTuningResNet50_DefaultAdam_WeightedMultiLabelLogLoss\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.1524\n",
      "val Loss: 0.1483\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 24m 50s\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.1432\n",
      "val Loss: 0.1701\n",
      "Epoch time elapsed: 20m 18s\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.1389\n",
      "val Loss: 0.1392\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 42s\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1346\n",
      "val Loss: 0.1392\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 52s\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1309\n",
      "val Loss: 0.1372\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 48s\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1282\n",
      "val Loss: 0.1377\n",
      "Epoch time elapsed: 19m 45s\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.1254\n",
      "val Loss: 0.1378\n",
      "Epoch time elapsed: 19m 45s\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.1236\n",
      "val Loss: 0.1235\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 46s\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.1217\n",
      "val Loss: 0.1224\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 45s\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.1199\n",
      "val Loss: 0.1167\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 49s\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.1178\n",
      "val Loss: 0.1221\n",
      "Epoch time elapsed: 19m 48s\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.1163\n",
      "val Loss: 0.1211\n",
      "Epoch time elapsed: 19m 46s\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.1148\n",
      "val Loss: 0.1226\n",
      "Epoch time elapsed: 19m 41s\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1139\n",
      "val Loss: 0.1155\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 42s\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.1126\n",
      "val Loss: 0.1143\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 19m 57s\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.1110\n",
      "val Loss: 0.1148\n",
      "Epoch time elapsed: 21m 53s\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.1103\n",
      "val Loss: 0.1125\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 21m 47s\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.1093\n",
      "val Loss: 0.1128\n",
      "Epoch time elapsed: 21m 45s\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1084\n",
      "val Loss: 0.1151\n",
      "Epoch time elapsed: 21m 40s\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1069\n",
      "val Loss: 0.1118\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 21m 42s\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1064\n",
      "val Loss: 0.1113\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 21m 46s\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_name_list = []\n",
    "metric_list = []\n",
    "\n",
    "for m in MODELS:\n",
    "    for o in OPTIMIZERS:\n",
    "        for l in LOSSES:\n",
    "            \n",
    "            model = getModel(m, NUM_CLASSES)\n",
    "            \n",
    "            optimizer = getOptimizer(o, model)\n",
    "            \n",
    "            criterion = getLossFunction(l)\n",
    "            \n",
    "            model_name = f'{m}_{o}_{l}'\n",
    "            \n",
    "            tensorboard = SummaryWriter(comment = model_name)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model, best_metric = train_model(\n",
    "                model, \n",
    "                model_name, \n",
    "                dataloaders_dict, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                num_epochs=NUM_EPOCH, \n",
    "                is_inception=MODEL_LIST[m]['is_inception'])\n",
    "            \n",
    "            model_name_list.append(model_name)\n",
    "            metric_list.append(best_metric)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(metric_list))  # the x locations for the groups\n",
    "ax.barh(ind, metric_list, width)\n",
    "ax.set_yticks(ind+width/2)\n",
    "ax.set_yticklabels(model_name_list, minor=False)\n",
    "plt.xlabel('Loss')\n",
    "for i, v in enumerate(metric_list):\n",
    "    ax.text(v, i, str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name_list)\n",
    "print(metric_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE_FRAC = 0.01\n",
    "['PreEfficientNet_DefaultAdam_WeightedMultiLabelLogLoss', 'PreDensenet121_DefaultAdam_WeightedMultiLabelLogLoss', 'PreVGG16_DefaultAdam_WeightedMultiLabelLogLoss', 'PreResNet50_DefaultAdam_WeightedMultiLabelLogLoss']\n",
    "[0.2597252761325229, 0.18248862174864647, 0.1948435460864637, 0.18010420099840774]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE_FRAC = 0.01\n",
    "['PreEfficientNet_DefaultAdam_WeightedMultiLabelLogLoss', 'PreDensenet121_DefaultAdam_WeightedMultiLabelLogLoss', 'PreVGG16_DefaultAdam_WeightedMultiLabelLogLoss', 'PreResNet50_DefaultAdam_WeightedMultiLabelLogLoss']\n",
    "[1.9888162942906151, 0.6419779309469817, 0.6130052950496551, 0.6645991335808494]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE_FRAC = 0.10\n",
    "['PreEfficientNet_DefaultAdam_WeightedMultiLabelLogLoss', 'PreDensenet121_DefaultAdam_WeightedMultiLabelLogLoss', 'PreVGG16_DefaultAdam_WeightedMultiLabelLogLoss', 'PreResNet50_DefaultAdam_WeightedMultiLabelLogLoss']\n",
    "[2.0618010826537043, 0.5627026143388972, 0.5728568886494199, 0.5545951228073894]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
