{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#import glob\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import densenet121, vgg16, resnet50, inception_v3\n",
    "from common.nets import ResNet50Attention\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from common.myfunctions import plot_confusion_matrix\n",
    "from common.customloss import QuadraticKappa, WeightedMultiLabelLogLoss, WeightedMultiLabelFocalLogLoss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/srv/app/data'\n",
    "\n",
    "DATA_DIR = BASE_DIR + '/data'\n",
    "\n",
    "MODEL_DIR = BASE_DIR + '/models'\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + '/numpy_array/stage_1_train_images_299_roi_interpolated'\n",
    "#Same path because we split train in train and test.\n",
    "TEST_DIR = DATA_DIR + '/numpy_array/stage_1_train_images_299_roi_interpolated' \n",
    "\n",
    "TRAIN_LABELS = DATA_DIR + '/stage_1_train_pivoted.csv'\n",
    "TEST_LABELS = DATA_DIR + ''\n",
    "\n",
    "BATCH_SIZE = 168\n",
    "\n",
    "NUM_EPOCH = 30\n",
    "\n",
    "TEST_SPLIT = 0.3\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "LABEL_COLUMN = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "INPUT_SIZE = 299\n",
    "\n",
    "IMAGE_FORMAT = 'npy'\n",
    "\n",
    "# MODELS = ['FineTuningResNet50Attention', 'FineTuningDensenet121']\n",
    "MODELS = ['FineTuningDensenet121']\n",
    "\n",
    "OPTIMIZERS = ['SGDMomentum']\n",
    "\n",
    "LOSSES = ['WeightedMultiLabelLogLoss']\n",
    "\n",
    "#DATASETS = ['WLWW_4040_50100_6040']\n",
    "\n",
    "SAMPLE_FRAC = 0.5 #Fraction of dataset to use. Set to 1.0 to use the entire dataset.\n",
    "\n",
    "CUDA_DEVICES = [1,2,3]\n",
    "\n",
    "BLACK_LIST_ID = ['ID_6431af929', 'ID_8da38f2e4', 'ID_0e21abf7a', 'ID_470e639ae', 'ID_d91d52bdc', \n",
    "                 'ID_dfcb69305', 'ID_5005bcb25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = {\n",
    "    'PreDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3', \n",
    "                             'denseblock4', 'norm5']\n",
    "    },\n",
    "    'FineTuningDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningDensenet121v1': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3']\n",
    "    },\n",
    "    'FineTuningDensenet121v2': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningDensenet121v1',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2']\n",
    "    },\n",
    "    'PreVGG16': {\n",
    "        'base_model': 'vgg16',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['features.0', 'features.2', 'features.5', 'features.7', \n",
    "                             'features.10', 'features.12', 'features.14', 'features.17', \n",
    "                             'features.19', 'features.21', 'features.24', 'features.26', \n",
    "                             'features.28', 'classifier.0', 'classifier.3']\n",
    "    },\n",
    "    'PreResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "    },\n",
    "    'FineTuningResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50Attention': {\n",
    "        'base_model': 'ResNet50Attention',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50v1': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "    },\n",
    "    'FineTuningResNet50v2': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningResNet50v1',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "    },\n",
    "    'PreInceptionV3': {\n",
    "        'base_model': 'inception_v3',\n",
    "        'is_inception': True,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['AuxLogits.conv0', 'AuxLogits.conv1', 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', \n",
    "                             'Conv2d_2b_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', \n",
    "                             'Mixed_5b.branch1x1', 'Mixed_5b.branch3x3dbl_1', \n",
    "                             'Mixed_5b.branch3x3dbl_2', 'Mixed_5b.branch3x3dbl_3', 'Mixed_5b.branch5x5_1', \n",
    "                             'Mixed_5b.branch5x5_2', 'Mixed_5b.branch_pool', 'Mixed_5c.branch1x1', \n",
    "                             'Mixed_5c.branch3x3dbl_1', 'Mixed_5c.branch3x3dbl_2', 'Mixed_5c.branch3x3dbl_3', \n",
    "                             'Mixed_5c.branch5x5_1', 'Mixed_5c.branch5x5_2', 'Mixed_5c.branch_pool', \n",
    "                             'Mixed_5d.branch1x1', 'Mixed_5d.branch3x3dbl_1', 'Mixed_5d.branch3x3dbl_2', \n",
    "                             'Mixed_5d.branch3x3dbl_3', 'Mixed_5d.branch5x5_1', 'Mixed_5d.branch5x5_2', \n",
    "                             'Mixed_5d.branch_pool', 'Mixed_6a.branch3x3', 'Mixed_6a.branch3x3dbl_1', \n",
    "                             'Mixed_6a.branch3x3dbl_2', 'Mixed_6a.branch3x3dbl_3', 'Mixed_6b.branch1x1', \n",
    "                             'Mixed_6b.branch7x7_1', 'Mixed_6b.branch7x7_2', 'Mixed_6b.branch7x7_3', \n",
    "                             'Mixed_6b.branch7x7dbl_1', 'Mixed_6b.branch7x7dbl_2', 'Mixed_6b.branch7x7dbl_3', \n",
    "                             'Mixed_6b.branch7x7dbl_4', 'Mixed_6b.branch7x7dbl_5', 'Mixed_6b.branch_pool', \n",
    "                             'Mixed_6c.branch1x1', 'Mixed_6c.branch7x7_1', 'Mixed_6c.branch7x7_2', \n",
    "                             'Mixed_6c.branch7x7_3', 'Mixed_6c.branch7x7dbl_1', 'Mixed_6c.branch7x7dbl_2', \n",
    "                             'Mixed_6c.branch7x7dbl_3', 'Mixed_6c.branch7x7dbl_4', 'Mixed_6c.branch7x7dbl_5', \n",
    "                             'Mixed_6c.branch_pool', 'Mixed_6d.branch1x1', 'Mixed_6d.branch7x7_1', \n",
    "                             'Mixed_6d.branch7x7_2', 'Mixed_6d.branch7x7_3', 'Mixed_6d.branch7x7dbl_1', \n",
    "                             'Mixed_6d.branch7x7dbl_2', 'Mixed_6d.branch7x7dbl_3', 'Mixed_6d.branch7x7dbl_4', \n",
    "                             'Mixed_6d.branch7x7dbl_5', 'Mixed_6d.branch_pool', 'Mixed_6e.branch1x1', \n",
    "                             'Mixed_6e.branch7x7_1', 'Mixed_6e.branch7x7_2', 'Mixed_6e.branch7x7_3', \n",
    "                             'Mixed_6e.branch7x7dbl_1', 'Mixed_6e.branch7x7dbl_2', 'Mixed_6e.branch7x7dbl_3', \n",
    "                             'Mixed_6e.branch7x7dbl_4', 'Mixed_6e.branch7x7dbl_5', 'Mixed_6e.branch_pool', \n",
    "                             'Mixed_7a.branch3x3_1', 'Mixed_7a.branch3x3_2', 'Mixed_7a.branch7x7x3_1', \n",
    "                             'Mixed_7a.branch7x7x3_2', 'Mixed_7a.branch7x7x3_3', 'Mixed_7a.branch7x7x3_4', \n",
    "                             'Mixed_7b.branch1x1', 'Mixed_7b.branch3x3_1', 'Mixed_7b.branch3x3_2a', \n",
    "                             'Mixed_7b.branch3x3_2b', 'Mixed_7b.branch3x3dbl_1', 'Mixed_7b.branch3x3dbl_2', \n",
    "                             'Mixed_7b.branch3x3dbl_3a', 'Mixed_7b.branch3x3dbl_3b', 'Mixed_7b.branch_pool', \n",
    "                             'Mixed_7c.branch1x1', 'Mixed_7c.branch3x3_1', 'Mixed_7c.branch3x3_2a', \n",
    "                             'Mixed_7c.branch3x3_2b', 'Mixed_7c.branch3x3dbl_1', 'Mixed_7c.branch3x3dbl_2', \n",
    "                             'Mixed_7c.branch3x3dbl_3a', 'Mixed_7c.branch3x3dbl_3b', 'Mixed_7c.branch_pool']\n",
    "    },\n",
    "    'PreEfficientNetB7': {\n",
    "        'base_model': 'efficientnetb7',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['_conv_stem', '_bn0', '_blocks', '_conv_head', '_bn1']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER_LIST = {\n",
    "    'DefaultAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.001,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'HalfLRAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.0005,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'DoubleWDAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.001,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0.0001,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'SGDMomentum': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.1,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "LOSS_LIST = {\n",
    "    'DefaultNLLLoss': {\n",
    "        'function': 'NLLLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultSmoothL1Loss': {\n",
    "        'function': 'SmoothL1Loss',\n",
    "        'size_average': None,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultCrossEntropyLoss': {\n",
    "        'function': 'CrossEntropyLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'QuadraticKappa': {\n",
    "        'function': 'QuadraticKappa',\n",
    "        'n_classes': NUM_CLASSES\n",
    "    },\n",
    "    'WeightedMultiLabelLogLoss': {\n",
    "        'function': 'WeightedMultiLabelLogLoss',\n",
    "        'n_classes': NUM_CLASSES,\n",
    "        'weight': None\n",
    "    },\n",
    "    'WeightedMultiLabelFocalLogLoss': {\n",
    "        'function': 'WeightedMultiLabelFocalLogLoss',\n",
    "        'n_classes': NUM_CLASSES,\n",
    "        'weight': None,\n",
    "        'gamma': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "#DATASET_LIST = {\n",
    "#    'WLWW_4040_50100_6040': {\n",
    "#        'convert_BGR2RGB': False,\n",
    "#        'normalize_255': False,\n",
    "#        'channels': 3,\n",
    "#        'channels_first': True,\n",
    "#        'custom_function': None\n",
    "#    },\n",
    "#    'WLWW_4040': {\n",
    "#        'train_dir': DATA_DIR + '/numpy_array/stage_1_train_images_299',\n",
    "#        'val_dir': None,\n",
    "#        'test_dir': DATA_DIR + '/numpy_array/stage_1_train_images_299'\n",
    "#        'convert_BGR2RGB': False,\n",
    "#        'normalize_255': False,\n",
    "#        'channels': 3,\n",
    "#        'channels_first': True,\n",
    "#        'custom_function': None\n",
    "#    }\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)    \n",
    "\n",
    "# Detect if we have a GPU available\n",
    "cuda_list = ','.join(str(c) for c in CUDA_DEVICES)\n",
    "device = torch.device(\"cuda:{}\".format(cuda_list) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, img_folder, img_ext='png', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (dataframe): Dataframe with images ID.\n",
    "            y (dataframe): Dataframe with labels annotations.\n",
    "            img_folder (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.img_folder = img_folder\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "        \n",
    "       #image = np.load(img_name).astype('uint8')\n",
    "        image = np.load(img_name)\n",
    "        \n",
    "        label = self.y.iloc[idx].to_numpy()\n",
    "        \n",
    "        if self.transform:\n",
    "       \n",
    "           image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "        return (image,label)\n",
    "    \n",
    "# class CustomDataset_v2(Dataset):\n",
    "\n",
    "#     def __init__(self, X, y, img_folder, img_ext='png', transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             X (dataframe): Dataframe with images ID.\n",
    "#             y (dataframe): Dataframe with labels annotations.\n",
    "#             img_folder (string): Directory with all the images.\n",
    "#             transform (callable, optional): Optional transform to be applied\n",
    "#                 on a sample.\n",
    "#         \"\"\"\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.img_folder = img_folder\n",
    "#         self.img_ext = img_ext\n",
    "#         self.transform = transform\n",
    "#         self.hu_min = -1024 # Min value of Hounsfield scale\n",
    "#         self.hu_max = 3071 # Max value of Hounsfield scale\n",
    "#         self.hu_delta = self.hu_max - self.hu_min # Just to save calculation\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "#         #image = np.load(img_name).astype('uint8')\n",
    "#         image = np.load(img_name)\n",
    "        \n",
    "#         image = image[:,:,[2]]\n",
    "#         image = np.repeat(image, 3, axis=2)\n",
    "        \n",
    "#         label = self.y.iloc[idx].to_numpy()\n",
    "        \n",
    "#         if self.transform:\n",
    "        \n",
    "#             image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "#         return (image,label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN_LABELS)\n",
    "data = data.loc[~data.id.isin(BLACK_LIST_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f412015c908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    data = data.sample(frac = SAMPLE_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f40fc6a1080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39584831, 14.44490255,  1.17906749,  1.61494301,  1.19664038,\n",
       "        0.90782531])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distrib_freq = data[LABEL_COLUMN].sum().to_numpy()\n",
    "w_classes = distrib_freq.sum() / (NUM_CLASSES * distrib_freq)\n",
    "w_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Wrong Loss Function Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in LOSSES:\n",
    "    if 'weight' in LOSS_LIST[l]:\n",
    "        LOSS_LIST[l]['weight'] = torch.from_numpy(w_classes).to(device)\n",
    "    else:\n",
    "        raise Exception('You are trying to set weight in a loss function without weight parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(LABEL_COLUMN, axis=1)\n",
    "y = data[LABEL_COLUMN]\n",
    "\n",
    "# Criando o dataframe de treine e teste com base no dataframe anteriormente criado\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = TEST_SPLIT, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf = transforms.Compose([\n",
    "    transforms.RandomRotation((0,360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X=X_train, \n",
    "                              y=y_train, \n",
    "                              img_folder=TRAIN_DIR,\n",
    "                              img_ext=IMAGE_FORMAT, \n",
    "                              transform=train_transf)\n",
    "\n",
    "test_dataset = CustomDataset(X=X_test, \n",
    "                             y=y_test, \n",
    "                             img_folder=TEST_DIR, \n",
    "                             img_ext=IMAGE_FORMAT,\n",
    "                             transform=test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garregando os dados\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBestModel(model_name):\n",
    "    device = torch.device(\"cuda:{}\".format(cuda_list) if torch.cuda.is_available() else \"cpu\")\n",
    "    # Get lastest model file\n",
    "    list_of_files = glob.glob(MODEL_DIR + f'/*{model_name}*.pt') # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f'Loading model {latest_file}')\n",
    "    model = torch.load(latest_file, map_location=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name, num_classes):\n",
    "    \n",
    "    model_parameters = MODEL_LIST[model_name]\n",
    "    \n",
    "    if model_parameters['load_checkpoint']:\n",
    "        \n",
    "        model = loadBestModel(model_parameters['checkpoint_from'])\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        if model_parameters['base_model']=='densenet121':\n",
    "            \n",
    "            model = densenet121(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier = nn.Linear(1024, num_classes)   \n",
    "            \n",
    "        if model_parameters['base_model']=='vgg16':\n",
    "            \n",
    "            model = vgg16(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier[6] = nn.Linear(4096, num_classes) \n",
    "        \n",
    "        if model_parameters['base_model']=='resnet50':\n",
    "            \n",
    "            model = resnet50(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    " \n",
    "        if model_parameters['base_model']=='ResNet50Attention':\n",
    "            model = ResNet50Attention(num_classes, \n",
    "                                      attention=True, \n",
    "                                      pretrained=model_parameters['pretrained'])\n",
    "             \n",
    "        if model_parameters['base_model']=='inception_v3':\n",
    "            \n",
    "            model = inception_v3(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    "            model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            \n",
    "        elif model_parameters['base_model']=='efficientnetb7':\n",
    "            \n",
    "            model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "            model._fc = nn.Linear(2560, NUM_CLASSES) \n",
    "            \n",
    "        if (torch.cuda.device_count() > 1) & (not model_parameters['is_inception']):\n",
    "            if not CUDA_DEVICES:\n",
    "                print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "                model = nn.DataParallel(model) # When load checkpoint, the DataParallel is already in the model.\n",
    "            else:\n",
    "                print(\"Let's use\", CUDA_DEVICES, \"GPUs!\")\n",
    "                model = nn.DataParallel(model, device_ids = CUDA_DEVICES) # When load checkpoint, the DataParallel is already in the model.\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        for l in model_parameters['layers_to_frozen']:\n",
    "            if l in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    if is_cuda:\n",
    "        model = model.to(device)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizer(optimizer_name, model):\n",
    "\n",
    "    params_to_update = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "    \n",
    "        if param.requires_grad == True:\n",
    "        \n",
    "            params_to_update.append(param)\n",
    "            \n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    opt_parameters = OPTIMIZER_LIST[optimizer_name]\n",
    "\n",
    "    if opt_parameters['function'] == 'Adam':\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params_to_update, \n",
    "                                     lr = opt_parameters['lr'],\n",
    "                                     betas = opt_parameters['betas'],\n",
    "                                     eps = opt_parameters['eps'],\n",
    "                                     weight_decay = opt_parameters['weight_decay'],\n",
    "                                     amsgrad = opt_parameters['amsgrad']\n",
    "                                    )\n",
    "    elif opt_parameters['function'] == 'SGD':\n",
    "        \n",
    "        optimizer = torch.optim.SGD(params_to_update, \n",
    "                                     lr = opt_parameters['lr'],\n",
    "                                     weight_decay = opt_parameters['weight_decay'],\n",
    "                                     momentum = opt_parameters['momentum']\n",
    "                                    )\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossFunction(loss_nme):\n",
    "    \n",
    "    loss_parameters = LOSS_LIST[loss_nme]\n",
    "\n",
    "    if loss_parameters['function'] == 'SmoothL1Loss':\n",
    "        criterion = nn.SmoothL1Loss(\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'CrossEntropyLoss':\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'NLLLoss':\n",
    "\n",
    "        criterion = nn.NLLLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'QuadraticKappa':\n",
    "        criterion = QuadraticKappa(\n",
    "            n_classes = loss_parameters['n_classes']\n",
    "        )\n",
    "        \n",
    "    elif loss_parameters['function'] == 'WeightedMultiLabelLogLoss':\n",
    "\n",
    "        criterion = WeightedMultiLabelLogLoss(\n",
    "            n_classes = loss_parameters['n_classes'],\n",
    "            weight = loss_parameters['weight']\n",
    "        )\n",
    "    elif loss_parameters['function'] == 'WeightedMultiLabelFocalLogLoss':\n",
    "\n",
    "        criterion = WeightedMultiLabelFocalLogLoss(\n",
    "            n_classes = loss_parameters['n_classes'],\n",
    "            weight = loss_parameters['weight'],\n",
    "            gamma = loss_parameters['gamma']\n",
    "        )\n",
    "        \n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def onehot(labels, num_classes):\n",
    "    return torch.zeros(len(labels), num_classes).scatter_(1, labels.unsqueeze(1).cpu(), 1.).cuda()\n",
    "\n",
    "def train_model(model, model_name, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_loss = 999\n",
    "    \n",
    "    print(model_name)\n",
    "    print('-' * 100)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        epoch_since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            #running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        \n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        aux_outputs = torch.sigmoid(aux_outputs)\n",
    "                        \n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        outputs = model(inputs)\n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            #epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            #lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # Write loss into Tensorboard\n",
    "            tensorboard.add_scalar('Loss {}'.format(phase), epoch_loss, epoch)\n",
    "            #tensorboard.add_scalar('Acc {}'.format(phase), epoch_acc, epoch)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Saving the best model...')\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model, MODEL_DIR + '/' + model_name + '_imgsize' + str(INPUT_SIZE) + '_loss' + str(best_loss) + '.pt')\n",
    "            \n",
    "        epoch_time_elapsed = time.time() - epoch_since\n",
    "        print('Epoch time elapsed: {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('')\n",
    "\n",
    "    # load best model weights\n",
    "    model = loadBestModel(model_name)\n",
    "    return model, best_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [1, 2, 3] GPUs!\n",
      "\t module.features.conv0.weight\n",
      "\t module.features.norm0.weight\n",
      "\t module.features.norm0.bias\n",
      "\t module.features.denseblock1.denselayer1.norm1.weight\n",
      "\t module.features.denseblock1.denselayer1.norm1.bias\n",
      "\t module.features.denseblock1.denselayer1.conv1.weight\n",
      "\t module.features.denseblock1.denselayer1.norm2.weight\n",
      "\t module.features.denseblock1.denselayer1.norm2.bias\n",
      "\t module.features.denseblock1.denselayer1.conv2.weight\n",
      "\t module.features.denseblock1.denselayer2.norm1.weight\n",
      "\t module.features.denseblock1.denselayer2.norm1.bias\n",
      "\t module.features.denseblock1.denselayer2.conv1.weight\n",
      "\t module.features.denseblock1.denselayer2.norm2.weight\n",
      "\t module.features.denseblock1.denselayer2.norm2.bias\n",
      "\t module.features.denseblock1.denselayer2.conv2.weight\n",
      "\t module.features.denseblock1.denselayer3.norm1.weight\n",
      "\t module.features.denseblock1.denselayer3.norm1.bias\n",
      "\t module.features.denseblock1.denselayer3.conv1.weight\n",
      "\t module.features.denseblock1.denselayer3.norm2.weight\n",
      "\t module.features.denseblock1.denselayer3.norm2.bias\n",
      "\t module.features.denseblock1.denselayer3.conv2.weight\n",
      "\t module.features.denseblock1.denselayer4.norm1.weight\n",
      "\t module.features.denseblock1.denselayer4.norm1.bias\n",
      "\t module.features.denseblock1.denselayer4.conv1.weight\n",
      "\t module.features.denseblock1.denselayer4.norm2.weight\n",
      "\t module.features.denseblock1.denselayer4.norm2.bias\n",
      "\t module.features.denseblock1.denselayer4.conv2.weight\n",
      "\t module.features.denseblock1.denselayer5.norm1.weight\n",
      "\t module.features.denseblock1.denselayer5.norm1.bias\n",
      "\t module.features.denseblock1.denselayer5.conv1.weight\n",
      "\t module.features.denseblock1.denselayer5.norm2.weight\n",
      "\t module.features.denseblock1.denselayer5.norm2.bias\n",
      "\t module.features.denseblock1.denselayer5.conv2.weight\n",
      "\t module.features.denseblock1.denselayer6.norm1.weight\n",
      "\t module.features.denseblock1.denselayer6.norm1.bias\n",
      "\t module.features.denseblock1.denselayer6.conv1.weight\n",
      "\t module.features.denseblock1.denselayer6.norm2.weight\n",
      "\t module.features.denseblock1.denselayer6.norm2.bias\n",
      "\t module.features.denseblock1.denselayer6.conv2.weight\n",
      "\t module.features.transition1.norm.weight\n",
      "\t module.features.transition1.norm.bias\n",
      "\t module.features.transition1.conv.weight\n",
      "\t module.features.denseblock2.denselayer1.norm1.weight\n",
      "\t module.features.denseblock2.denselayer1.norm1.bias\n",
      "\t module.features.denseblock2.denselayer1.conv1.weight\n",
      "\t module.features.denseblock2.denselayer1.norm2.weight\n",
      "\t module.features.denseblock2.denselayer1.norm2.bias\n",
      "\t module.features.denseblock2.denselayer1.conv2.weight\n",
      "\t module.features.denseblock2.denselayer2.norm1.weight\n",
      "\t module.features.denseblock2.denselayer2.norm1.bias\n",
      "\t module.features.denseblock2.denselayer2.conv1.weight\n",
      "\t module.features.denseblock2.denselayer2.norm2.weight\n",
      "\t module.features.denseblock2.denselayer2.norm2.bias\n",
      "\t module.features.denseblock2.denselayer2.conv2.weight\n",
      "\t module.features.denseblock2.denselayer3.norm1.weight\n",
      "\t module.features.denseblock2.denselayer3.norm1.bias\n",
      "\t module.features.denseblock2.denselayer3.conv1.weight\n",
      "\t module.features.denseblock2.denselayer3.norm2.weight\n",
      "\t module.features.denseblock2.denselayer3.norm2.bias\n",
      "\t module.features.denseblock2.denselayer3.conv2.weight\n",
      "\t module.features.denseblock2.denselayer4.norm1.weight\n",
      "\t module.features.denseblock2.denselayer4.norm1.bias\n",
      "\t module.features.denseblock2.denselayer4.conv1.weight\n",
      "\t module.features.denseblock2.denselayer4.norm2.weight\n",
      "\t module.features.denseblock2.denselayer4.norm2.bias\n",
      "\t module.features.denseblock2.denselayer4.conv2.weight\n",
      "\t module.features.denseblock2.denselayer5.norm1.weight\n",
      "\t module.features.denseblock2.denselayer5.norm1.bias\n",
      "\t module.features.denseblock2.denselayer5.conv1.weight\n",
      "\t module.features.denseblock2.denselayer5.norm2.weight\n",
      "\t module.features.denseblock2.denselayer5.norm2.bias\n",
      "\t module.features.denseblock2.denselayer5.conv2.weight\n",
      "\t module.features.denseblock2.denselayer6.norm1.weight\n",
      "\t module.features.denseblock2.denselayer6.norm1.bias\n",
      "\t module.features.denseblock2.denselayer6.conv1.weight\n",
      "\t module.features.denseblock2.denselayer6.norm2.weight\n",
      "\t module.features.denseblock2.denselayer6.norm2.bias\n",
      "\t module.features.denseblock2.denselayer6.conv2.weight\n",
      "\t module.features.denseblock2.denselayer7.norm1.weight\n",
      "\t module.features.denseblock2.denselayer7.norm1.bias\n",
      "\t module.features.denseblock2.denselayer7.conv1.weight\n",
      "\t module.features.denseblock2.denselayer7.norm2.weight\n",
      "\t module.features.denseblock2.denselayer7.norm2.bias\n",
      "\t module.features.denseblock2.denselayer7.conv2.weight\n",
      "\t module.features.denseblock2.denselayer8.norm1.weight\n",
      "\t module.features.denseblock2.denselayer8.norm1.bias\n",
      "\t module.features.denseblock2.denselayer8.conv1.weight\n",
      "\t module.features.denseblock2.denselayer8.norm2.weight\n",
      "\t module.features.denseblock2.denselayer8.norm2.bias\n",
      "\t module.features.denseblock2.denselayer8.conv2.weight\n",
      "\t module.features.denseblock2.denselayer9.norm1.weight\n",
      "\t module.features.denseblock2.denselayer9.norm1.bias\n",
      "\t module.features.denseblock2.denselayer9.conv1.weight\n",
      "\t module.features.denseblock2.denselayer9.norm2.weight\n",
      "\t module.features.denseblock2.denselayer9.norm2.bias\n",
      "\t module.features.denseblock2.denselayer9.conv2.weight\n",
      "\t module.features.denseblock2.denselayer10.norm1.weight\n",
      "\t module.features.denseblock2.denselayer10.norm1.bias\n",
      "\t module.features.denseblock2.denselayer10.conv1.weight\n",
      "\t module.features.denseblock2.denselayer10.norm2.weight\n",
      "\t module.features.denseblock2.denselayer10.norm2.bias\n",
      "\t module.features.denseblock2.denselayer10.conv2.weight\n",
      "\t module.features.denseblock2.denselayer11.norm1.weight\n",
      "\t module.features.denseblock2.denselayer11.norm1.bias\n",
      "\t module.features.denseblock2.denselayer11.conv1.weight\n",
      "\t module.features.denseblock2.denselayer11.norm2.weight\n",
      "\t module.features.denseblock2.denselayer11.norm2.bias\n",
      "\t module.features.denseblock2.denselayer11.conv2.weight\n",
      "\t module.features.denseblock2.denselayer12.norm1.weight\n",
      "\t module.features.denseblock2.denselayer12.norm1.bias\n",
      "\t module.features.denseblock2.denselayer12.conv1.weight\n",
      "\t module.features.denseblock2.denselayer12.norm2.weight\n",
      "\t module.features.denseblock2.denselayer12.norm2.bias\n",
      "\t module.features.denseblock2.denselayer12.conv2.weight\n",
      "\t module.features.transition2.norm.weight\n",
      "\t module.features.transition2.norm.bias\n",
      "\t module.features.transition2.conv.weight\n",
      "\t module.features.denseblock3.denselayer1.norm1.weight\n",
      "\t module.features.denseblock3.denselayer1.norm1.bias\n",
      "\t module.features.denseblock3.denselayer1.conv1.weight\n",
      "\t module.features.denseblock3.denselayer1.norm2.weight\n",
      "\t module.features.denseblock3.denselayer1.norm2.bias\n",
      "\t module.features.denseblock3.denselayer1.conv2.weight\n",
      "\t module.features.denseblock3.denselayer2.norm1.weight\n",
      "\t module.features.denseblock3.denselayer2.norm1.bias\n",
      "\t module.features.denseblock3.denselayer2.conv1.weight\n",
      "\t module.features.denseblock3.denselayer2.norm2.weight\n",
      "\t module.features.denseblock3.denselayer2.norm2.bias\n",
      "\t module.features.denseblock3.denselayer2.conv2.weight\n",
      "\t module.features.denseblock3.denselayer3.norm1.weight\n",
      "\t module.features.denseblock3.denselayer3.norm1.bias\n",
      "\t module.features.denseblock3.denselayer3.conv1.weight\n",
      "\t module.features.denseblock3.denselayer3.norm2.weight\n",
      "\t module.features.denseblock3.denselayer3.norm2.bias\n",
      "\t module.features.denseblock3.denselayer3.conv2.weight\n",
      "\t module.features.denseblock3.denselayer4.norm1.weight\n",
      "\t module.features.denseblock3.denselayer4.norm1.bias\n",
      "\t module.features.denseblock3.denselayer4.conv1.weight\n",
      "\t module.features.denseblock3.denselayer4.norm2.weight\n",
      "\t module.features.denseblock3.denselayer4.norm2.bias\n",
      "\t module.features.denseblock3.denselayer4.conv2.weight\n",
      "\t module.features.denseblock3.denselayer5.norm1.weight\n",
      "\t module.features.denseblock3.denselayer5.norm1.bias\n",
      "\t module.features.denseblock3.denselayer5.conv1.weight\n",
      "\t module.features.denseblock3.denselayer5.norm2.weight\n",
      "\t module.features.denseblock3.denselayer5.norm2.bias\n",
      "\t module.features.denseblock3.denselayer5.conv2.weight\n",
      "\t module.features.denseblock3.denselayer6.norm1.weight\n",
      "\t module.features.denseblock3.denselayer6.norm1.bias\n",
      "\t module.features.denseblock3.denselayer6.conv1.weight\n",
      "\t module.features.denseblock3.denselayer6.norm2.weight\n",
      "\t module.features.denseblock3.denselayer6.norm2.bias\n",
      "\t module.features.denseblock3.denselayer6.conv2.weight\n",
      "\t module.features.denseblock3.denselayer7.norm1.weight\n",
      "\t module.features.denseblock3.denselayer7.norm1.bias\n",
      "\t module.features.denseblock3.denselayer7.conv1.weight\n",
      "\t module.features.denseblock3.denselayer7.norm2.weight\n",
      "\t module.features.denseblock3.denselayer7.norm2.bias\n",
      "\t module.features.denseblock3.denselayer7.conv2.weight\n",
      "\t module.features.denseblock3.denselayer8.norm1.weight\n",
      "\t module.features.denseblock3.denselayer8.norm1.bias\n",
      "\t module.features.denseblock3.denselayer8.conv1.weight\n",
      "\t module.features.denseblock3.denselayer8.norm2.weight\n",
      "\t module.features.denseblock3.denselayer8.norm2.bias\n",
      "\t module.features.denseblock3.denselayer8.conv2.weight\n",
      "\t module.features.denseblock3.denselayer9.norm1.weight\n",
      "\t module.features.denseblock3.denselayer9.norm1.bias\n",
      "\t module.features.denseblock3.denselayer9.conv1.weight\n",
      "\t module.features.denseblock3.denselayer9.norm2.weight\n",
      "\t module.features.denseblock3.denselayer9.norm2.bias\n",
      "\t module.features.denseblock3.denselayer9.conv2.weight\n",
      "\t module.features.denseblock3.denselayer10.norm1.weight\n",
      "\t module.features.denseblock3.denselayer10.norm1.bias\n",
      "\t module.features.denseblock3.denselayer10.conv1.weight\n",
      "\t module.features.denseblock3.denselayer10.norm2.weight\n",
      "\t module.features.denseblock3.denselayer10.norm2.bias\n",
      "\t module.features.denseblock3.denselayer10.conv2.weight\n",
      "\t module.features.denseblock3.denselayer11.norm1.weight\n",
      "\t module.features.denseblock3.denselayer11.norm1.bias\n",
      "\t module.features.denseblock3.denselayer11.conv1.weight\n",
      "\t module.features.denseblock3.denselayer11.norm2.weight\n",
      "\t module.features.denseblock3.denselayer11.norm2.bias\n",
      "\t module.features.denseblock3.denselayer11.conv2.weight\n",
      "\t module.features.denseblock3.denselayer12.norm1.weight\n",
      "\t module.features.denseblock3.denselayer12.norm1.bias\n",
      "\t module.features.denseblock3.denselayer12.conv1.weight\n",
      "\t module.features.denseblock3.denselayer12.norm2.weight\n",
      "\t module.features.denseblock3.denselayer12.norm2.bias\n",
      "\t module.features.denseblock3.denselayer12.conv2.weight\n",
      "\t module.features.denseblock3.denselayer13.norm1.weight\n",
      "\t module.features.denseblock3.denselayer13.norm1.bias\n",
      "\t module.features.denseblock3.denselayer13.conv1.weight\n",
      "\t module.features.denseblock3.denselayer13.norm2.weight\n",
      "\t module.features.denseblock3.denselayer13.norm2.bias\n",
      "\t module.features.denseblock3.denselayer13.conv2.weight\n",
      "\t module.features.denseblock3.denselayer14.norm1.weight\n",
      "\t module.features.denseblock3.denselayer14.norm1.bias\n",
      "\t module.features.denseblock3.denselayer14.conv1.weight\n",
      "\t module.features.denseblock3.denselayer14.norm2.weight\n",
      "\t module.features.denseblock3.denselayer14.norm2.bias\n",
      "\t module.features.denseblock3.denselayer14.conv2.weight\n",
      "\t module.features.denseblock3.denselayer15.norm1.weight\n",
      "\t module.features.denseblock3.denselayer15.norm1.bias\n",
      "\t module.features.denseblock3.denselayer15.conv1.weight\n",
      "\t module.features.denseblock3.denselayer15.norm2.weight\n",
      "\t module.features.denseblock3.denselayer15.norm2.bias\n",
      "\t module.features.denseblock3.denselayer15.conv2.weight\n",
      "\t module.features.denseblock3.denselayer16.norm1.weight\n",
      "\t module.features.denseblock3.denselayer16.norm1.bias\n",
      "\t module.features.denseblock3.denselayer16.conv1.weight\n",
      "\t module.features.denseblock3.denselayer16.norm2.weight\n",
      "\t module.features.denseblock3.denselayer16.norm2.bias\n",
      "\t module.features.denseblock3.denselayer16.conv2.weight\n",
      "\t module.features.denseblock3.denselayer17.norm1.weight\n",
      "\t module.features.denseblock3.denselayer17.norm1.bias\n",
      "\t module.features.denseblock3.denselayer17.conv1.weight\n",
      "\t module.features.denseblock3.denselayer17.norm2.weight\n",
      "\t module.features.denseblock3.denselayer17.norm2.bias\n",
      "\t module.features.denseblock3.denselayer17.conv2.weight\n",
      "\t module.features.denseblock3.denselayer18.norm1.weight\n",
      "\t module.features.denseblock3.denselayer18.norm1.bias\n",
      "\t module.features.denseblock3.denselayer18.conv1.weight\n",
      "\t module.features.denseblock3.denselayer18.norm2.weight\n",
      "\t module.features.denseblock3.denselayer18.norm2.bias\n",
      "\t module.features.denseblock3.denselayer18.conv2.weight\n",
      "\t module.features.denseblock3.denselayer19.norm1.weight\n",
      "\t module.features.denseblock3.denselayer19.norm1.bias\n",
      "\t module.features.denseblock3.denselayer19.conv1.weight\n",
      "\t module.features.denseblock3.denselayer19.norm2.weight\n",
      "\t module.features.denseblock3.denselayer19.norm2.bias\n",
      "\t module.features.denseblock3.denselayer19.conv2.weight\n",
      "\t module.features.denseblock3.denselayer20.norm1.weight\n",
      "\t module.features.denseblock3.denselayer20.norm1.bias\n",
      "\t module.features.denseblock3.denselayer20.conv1.weight\n",
      "\t module.features.denseblock3.denselayer20.norm2.weight\n",
      "\t module.features.denseblock3.denselayer20.norm2.bias\n",
      "\t module.features.denseblock3.denselayer20.conv2.weight\n",
      "\t module.features.denseblock3.denselayer21.norm1.weight\n",
      "\t module.features.denseblock3.denselayer21.norm1.bias\n",
      "\t module.features.denseblock3.denselayer21.conv1.weight\n",
      "\t module.features.denseblock3.denselayer21.norm2.weight\n",
      "\t module.features.denseblock3.denselayer21.norm2.bias\n",
      "\t module.features.denseblock3.denselayer21.conv2.weight\n",
      "\t module.features.denseblock3.denselayer22.norm1.weight\n",
      "\t module.features.denseblock3.denselayer22.norm1.bias\n",
      "\t module.features.denseblock3.denselayer22.conv1.weight\n",
      "\t module.features.denseblock3.denselayer22.norm2.weight\n",
      "\t module.features.denseblock3.denselayer22.norm2.bias\n",
      "\t module.features.denseblock3.denselayer22.conv2.weight\n",
      "\t module.features.denseblock3.denselayer23.norm1.weight\n",
      "\t module.features.denseblock3.denselayer23.norm1.bias\n",
      "\t module.features.denseblock3.denselayer23.conv1.weight\n",
      "\t module.features.denseblock3.denselayer23.norm2.weight\n",
      "\t module.features.denseblock3.denselayer23.norm2.bias\n",
      "\t module.features.denseblock3.denselayer23.conv2.weight\n",
      "\t module.features.denseblock3.denselayer24.norm1.weight\n",
      "\t module.features.denseblock3.denselayer24.norm1.bias\n",
      "\t module.features.denseblock3.denselayer24.conv1.weight\n",
      "\t module.features.denseblock3.denselayer24.norm2.weight\n",
      "\t module.features.denseblock3.denselayer24.norm2.bias\n",
      "\t module.features.denseblock3.denselayer24.conv2.weight\n",
      "\t module.features.transition3.norm.weight\n",
      "\t module.features.transition3.norm.bias\n",
      "\t module.features.transition3.conv.weight\n",
      "\t module.features.denseblock4.denselayer1.norm1.weight\n",
      "\t module.features.denseblock4.denselayer1.norm1.bias\n",
      "\t module.features.denseblock4.denselayer1.conv1.weight\n",
      "\t module.features.denseblock4.denselayer1.norm2.weight\n",
      "\t module.features.denseblock4.denselayer1.norm2.bias\n",
      "\t module.features.denseblock4.denselayer1.conv2.weight\n",
      "\t module.features.denseblock4.denselayer2.norm1.weight\n",
      "\t module.features.denseblock4.denselayer2.norm1.bias\n",
      "\t module.features.denseblock4.denselayer2.conv1.weight\n",
      "\t module.features.denseblock4.denselayer2.norm2.weight\n",
      "\t module.features.denseblock4.denselayer2.norm2.bias\n",
      "\t module.features.denseblock4.denselayer2.conv2.weight\n",
      "\t module.features.denseblock4.denselayer3.norm1.weight\n",
      "\t module.features.denseblock4.denselayer3.norm1.bias\n",
      "\t module.features.denseblock4.denselayer3.conv1.weight\n",
      "\t module.features.denseblock4.denselayer3.norm2.weight\n",
      "\t module.features.denseblock4.denselayer3.norm2.bias\n",
      "\t module.features.denseblock4.denselayer3.conv2.weight\n",
      "\t module.features.denseblock4.denselayer4.norm1.weight\n",
      "\t module.features.denseblock4.denselayer4.norm1.bias\n",
      "\t module.features.denseblock4.denselayer4.conv1.weight\n",
      "\t module.features.denseblock4.denselayer4.norm2.weight\n",
      "\t module.features.denseblock4.denselayer4.norm2.bias\n",
      "\t module.features.denseblock4.denselayer4.conv2.weight\n",
      "\t module.features.denseblock4.denselayer5.norm1.weight\n",
      "\t module.features.denseblock4.denselayer5.norm1.bias\n",
      "\t module.features.denseblock4.denselayer5.conv1.weight\n",
      "\t module.features.denseblock4.denselayer5.norm2.weight\n",
      "\t module.features.denseblock4.denselayer5.norm2.bias\n",
      "\t module.features.denseblock4.denselayer5.conv2.weight\n",
      "\t module.features.denseblock4.denselayer6.norm1.weight\n",
      "\t module.features.denseblock4.denselayer6.norm1.bias\n",
      "\t module.features.denseblock4.denselayer6.conv1.weight\n",
      "\t module.features.denseblock4.denselayer6.norm2.weight\n",
      "\t module.features.denseblock4.denselayer6.norm2.bias\n",
      "\t module.features.denseblock4.denselayer6.conv2.weight\n",
      "\t module.features.denseblock4.denselayer7.norm1.weight\n",
      "\t module.features.denseblock4.denselayer7.norm1.bias\n",
      "\t module.features.denseblock4.denselayer7.conv1.weight\n",
      "\t module.features.denseblock4.denselayer7.norm2.weight\n",
      "\t module.features.denseblock4.denselayer7.norm2.bias\n",
      "\t module.features.denseblock4.denselayer7.conv2.weight\n",
      "\t module.features.denseblock4.denselayer8.norm1.weight\n",
      "\t module.features.denseblock4.denselayer8.norm1.bias\n",
      "\t module.features.denseblock4.denselayer8.conv1.weight\n",
      "\t module.features.denseblock4.denselayer8.norm2.weight\n",
      "\t module.features.denseblock4.denselayer8.norm2.bias\n",
      "\t module.features.denseblock4.denselayer8.conv2.weight\n",
      "\t module.features.denseblock4.denselayer9.norm1.weight\n",
      "\t module.features.denseblock4.denselayer9.norm1.bias\n",
      "\t module.features.denseblock4.denselayer9.conv1.weight\n",
      "\t module.features.denseblock4.denselayer9.norm2.weight\n",
      "\t module.features.denseblock4.denselayer9.norm2.bias\n",
      "\t module.features.denseblock4.denselayer9.conv2.weight\n",
      "\t module.features.denseblock4.denselayer10.norm1.weight\n",
      "\t module.features.denseblock4.denselayer10.norm1.bias\n",
      "\t module.features.denseblock4.denselayer10.conv1.weight\n",
      "\t module.features.denseblock4.denselayer10.norm2.weight\n",
      "\t module.features.denseblock4.denselayer10.norm2.bias\n",
      "\t module.features.denseblock4.denselayer10.conv2.weight\n",
      "\t module.features.denseblock4.denselayer11.norm1.weight\n",
      "\t module.features.denseblock4.denselayer11.norm1.bias\n",
      "\t module.features.denseblock4.denselayer11.conv1.weight\n",
      "\t module.features.denseblock4.denselayer11.norm2.weight\n",
      "\t module.features.denseblock4.denselayer11.norm2.bias\n",
      "\t module.features.denseblock4.denselayer11.conv2.weight\n",
      "\t module.features.denseblock4.denselayer12.norm1.weight\n",
      "\t module.features.denseblock4.denselayer12.norm1.bias\n",
      "\t module.features.denseblock4.denselayer12.conv1.weight\n",
      "\t module.features.denseblock4.denselayer12.norm2.weight\n",
      "\t module.features.denseblock4.denselayer12.norm2.bias\n",
      "\t module.features.denseblock4.denselayer12.conv2.weight\n",
      "\t module.features.denseblock4.denselayer13.norm1.weight\n",
      "\t module.features.denseblock4.denselayer13.norm1.bias\n",
      "\t module.features.denseblock4.denselayer13.conv1.weight\n",
      "\t module.features.denseblock4.denselayer13.norm2.weight\n",
      "\t module.features.denseblock4.denselayer13.norm2.bias\n",
      "\t module.features.denseblock4.denselayer13.conv2.weight\n",
      "\t module.features.denseblock4.denselayer14.norm1.weight\n",
      "\t module.features.denseblock4.denselayer14.norm1.bias\n",
      "\t module.features.denseblock4.denselayer14.conv1.weight\n",
      "\t module.features.denseblock4.denselayer14.norm2.weight\n",
      "\t module.features.denseblock4.denselayer14.norm2.bias\n",
      "\t module.features.denseblock4.denselayer14.conv2.weight\n",
      "\t module.features.denseblock4.denselayer15.norm1.weight\n",
      "\t module.features.denseblock4.denselayer15.norm1.bias\n",
      "\t module.features.denseblock4.denselayer15.conv1.weight\n",
      "\t module.features.denseblock4.denselayer15.norm2.weight\n",
      "\t module.features.denseblock4.denselayer15.norm2.bias\n",
      "\t module.features.denseblock4.denselayer15.conv2.weight\n",
      "\t module.features.denseblock4.denselayer16.norm1.weight\n",
      "\t module.features.denseblock4.denselayer16.norm1.bias\n",
      "\t module.features.denseblock4.denselayer16.conv1.weight\n",
      "\t module.features.denseblock4.denselayer16.norm2.weight\n",
      "\t module.features.denseblock4.denselayer16.norm2.bias\n",
      "\t module.features.denseblock4.denselayer16.conv2.weight\n",
      "\t module.features.norm5.weight\n",
      "\t module.features.norm5.bias\n",
      "\t module.classifier.weight\n",
      "\t module.classifier.bias\n",
      "FineTuningDensenet121_SGDMomentum_WeightedMultiLabelLogLoss\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1910\n",
      "val Loss: 0.1480\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 37m 26s\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.1428\n",
      "val Loss: 0.1334\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 27m 53s\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.1291\n",
      "val Loss: 0.1252\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 25m 22s\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_name_list = []\n",
    "metric_list = []\n",
    "\n",
    "for m in MODELS:\n",
    "    for o in OPTIMIZERS:\n",
    "        for l in LOSSES:\n",
    "            \n",
    "            model = getModel(m, NUM_CLASSES)\n",
    "            \n",
    "            optimizer = getOptimizer(o, model)\n",
    "            \n",
    "            criterion = getLossFunction(l)\n",
    "            \n",
    "            model_name = f'{m}_{o}_{l}'\n",
    "            \n",
    "            tensorboard = SummaryWriter(comment = model_name)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model, best_metric = train_model(\n",
    "                model, \n",
    "                model_name, \n",
    "                dataloaders_dict, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                num_epochs=NUM_EPOCH, \n",
    "                is_inception=MODEL_LIST[m]['is_inception'])\n",
    "            \n",
    "            model_name_list.append(model_name)\n",
    "            metric_list.append(best_metric)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(metric_list))  # the x locations for the groups\n",
    "ax.barh(ind, metric_list, width)\n",
    "ax.set_yticks(ind+width/2)\n",
    "ax.set_yticklabels(model_name_list, minor=False)\n",
    "plt.xlabel('Loss')\n",
    "for i, v in enumerate(metric_list):\n",
    "    ax.text(v, i, str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name_list)\n",
    "print(metric_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
