{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/.local/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import densenet121, vgg16, resnet50, inception_v3\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.externals.joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/srv/app/data'\n",
    "\n",
    "DATA_DIR = BASE_DIR + '/data'\n",
    "\n",
    "MODEL_DIR = BASE_DIR + '/models/'\n",
    "\n",
    "TEST_DIR = DATA_DIR + '/numpy_array/stage_2_test_images_299_roi_interpolated/'\n",
    "IMAGE_FORMAT = 'npy'\n",
    "\n",
    "BATCH_SIZE = 168\n",
    "\n",
    "LABEL_COLUMN = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "STACKING_MODEL = BASE_DIR + '/models/stackingRF.pkl'\n",
    "\n",
    "targets = ['ID', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "\n",
    "files_list = os.listdir(TEST_DIR)\n",
    "\n",
    "files_ids = [x.split('.')[0] for x in files_list]\n",
    "\n",
    "CUDA_DEVICES = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)    \n",
    "\n",
    "# Detect if we have a GPU available\n",
    "cuda_list = ','.join(str(c) for c in CUDA_DEVICES)\n",
    "device = torch.device(\"cuda:{}\".format(cuda_list) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78545"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPredictDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, img_folder, img_ext='png', transform=None, index=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (dataframe): Dataframe with images ID.\n",
    "            img_folder (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.img_folder = img_folder\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "        self.index = index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "        #image = np.load(img_name).astype('uint8')\n",
    "        image = np.load(img_name)\n",
    "        \n",
    "        if self.index:\n",
    "            image = image[:,:,[int(self.index)]]\n",
    "            image = np.repeat(image, 3, axis=2)\n",
    "        if self.transform:\n",
    "        \n",
    "            image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(files_ids, columns =['ID']) \n",
    "X_stack = pd.DataFrame(files_ids, columns =['ID']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictProbas(model, model_name, transform, layer=None):\n",
    "    global X_stack\n",
    "    dataset = CustomPredictDataset(\n",
    "                            X=X, \n",
    "                            img_folder=TEST_DIR, \n",
    "                            img_ext=IMAGE_FORMAT,\n",
    "                            transform=transform[1],\n",
    "                            index=layer\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    outputs = torch.zeros(1, 6).to(device)\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader):\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            if type(output) == tuple:\n",
    "                output = output[0]\n",
    "            output = torch.sigmoid(output)\n",
    "            outputs = torch.cat((outputs, output))\n",
    "    outputs = outputs[1:,:]\n",
    "    labels = [item+\"_\"+model_name+transform[0] for item in LABEL_COLUMN]\n",
    "    Y_pred = pd.DataFrame(outputs.tolist(), columns = labels)\n",
    "    Y_pred = Y_pred.reset_index(drop=True)\n",
    "    X_stack = X_stack.merge(Y_pred, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTimeAugmentationPredict(model, transform_list, layer=None):\n",
    "    loaded_model = torch.load(MODEL_DIR+model[1])\n",
    "    loaded_model.eval()\n",
    "    for transform in transform_list:\n",
    "        print('Transform {}'.format(str(transform)))\n",
    "        predict = predictProbas(loaded_model, model[0],transform, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackModelsTestTimeAugmentation(models_list, transform_list, layer=None):\n",
    "    for model in models_list:\n",
    "        print('Model: {}'.format(model[1]))\n",
    "        predict = testTimeAugmentationPredict(model, transform_list, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transfA1 = transforms.Compose([\n",
    "    transforms.RandomRotation((0,360)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transfA2 = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transfA3 = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transforms_list = [('T1', test_transf), ('T2', test_transfA1), ('T3', test_transfA2), ('T4', test_transfA3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FineTuningResNet50AttentionMultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.07666666343915433.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/78545 [00:00<52:41, 24.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform ('T1', Compose(\n",
      "    ToTensor()\n",
      "))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78545/78545 [28:59<00:00, 45.15it/s]\n",
      "  0%|          | 5/78545 [00:00<28:34, 45.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform ('T2', Compose(\n",
      "    RandomRotation(degrees=(0, 360), resample=False, expand=False)\n",
      "    ToTensor()\n",
      "))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 34266/78545 [12:42<17:35, 41.96it/s]"
     ]
    }
   ],
   "source": [
    "models = [('ResNet','FineTuningResNet50AttentionMultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.07118233637800009.pt'),\n",
    "         ('DenseNet','FineTuningDensenet121MultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.06919282247931359.pt')]\n",
    "\n",
    "stackModelsTestTimeAugmentation(models, transforms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = load(STACKING_MODEL)\n",
    "X_stacked = X_stack[stack['X_train_empty'].columns]\n",
    "\n",
    "Y_stack = stack['rf'].predict_proba(X_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_array = np.array(Y_stack)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    LABEL_COLUMN[0]: Y_array[0,:],\n",
    "    LABEL_COLUMN[1]: Y_array[1,:],\n",
    "    LABEL_COLUMN[2]: Y_array[2,:],\n",
    "    LABEL_COLUMN[3]: Y_array[3,:],\n",
    "    LABEL_COLUMN[4]: Y_array[4,:],\n",
    "    LABEL_COLUMN[5]: Y_array[5,:]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame.from_dict(data)\n",
    "Y = Y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78545"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = X.merge(Y, left_index = True, right_index = True)\n",
    "pred = pred[targets]\n",
    "pred = pd.melt(pred, id_vars=['ID'], value_vars=targets[1:])\n",
    "pred['ID'] = pred['ID']+'_'+pred['variable']\n",
    "pred = pred.drop('variable', axis =1)\n",
    "pred.columns = ['ID', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471270"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred) #471270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_8e9de75bb_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_d9a58cb3f_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_b63a27c4b_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_822c2893f_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_6e0130955_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Label\n",
       "0  ID_8e9de75bb_epidural    0.0\n",
       "1  ID_d9a58cb3f_epidural    0.0\n",
       "2  ID_b63a27c4b_epidural    0.0\n",
       "3  ID_822c2893f_epidural    0.0\n",
       "4  ID_6e0130955_epidural    0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(DATA_DIR + '/predicts/stage_2_pred02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
