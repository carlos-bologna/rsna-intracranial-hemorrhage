{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#import glob\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import densenet121, vgg16, resnet50, inception_v3\n",
    "from common.nets import ResNet50Attention, ResNet50AttentionMultiTask, densenet121multitask, \\\n",
    "    densenet121multitaskV2, ResNet50AttentionMultiTaskV2\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from common.myfunctions import plot_confusion_matrix\n",
    "from common.customloss import QuadraticKappa, WeightedMultiLabelLogLoss, WeightedMultiLabelFocalLogLoss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/srv/app/data'\n",
    "\n",
    "DATA_DIR = BASE_DIR + '/data'\n",
    "\n",
    "MODEL_DIR = BASE_DIR + '/models'\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + '/numpy_array/stage_2_train_images_299_roi_interpolated'\n",
    "#Same path because we split train in train and test.\n",
    "TEST_DIR = DATA_DIR + '/numpy_array/stage_2_train_images_299_roi_interpolated' \n",
    "\n",
    "TRAIN_LABELS = DATA_DIR + '/stage_2_train_pivoted_z.csv'\n",
    "TEST_LABELS = DATA_DIR + ''\n",
    "\n",
    "BATCH_SIZE = 168\n",
    "\n",
    "NUM_EPOCH = 30\n",
    "\n",
    "TEST_SPLIT = 0.3\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "LABEL_COLUMN = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "INPUT_SIZE = 299\n",
    "\n",
    "IMAGE_FORMAT = 'npy'\n",
    "\n",
    "MODELS = ['FineTuningDensenet121MultiTaskV2']\n",
    "\n",
    "OPTIMIZERS = ['SGDMomentumV7']\n",
    "\n",
    "LOSSES = ['WeightedMultiLabelLogLoss']\n",
    "\n",
    "#DATASETS = ['WLWW_4040_50100_6040']\n",
    "\n",
    "SAMPLE_FRAC = 1.0 #Fraction of dataset to use. Set to 1.0 to use the entire dataset.\n",
    "\n",
    "CUDA_DEVICES = [1,2,3]\n",
    "\n",
    "BLACK_LIST_ID = ['ID_6431af929', 'ID_8da38f2e4', 'ID_0e21abf7a', 'ID_470e639ae', 'ID_d91d52bdc', \n",
    "                 'ID_dfcb69305', 'ID_5005bcb25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = {\n",
    "    'PreDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3', \n",
    "                             'denseblock4', 'norm5']\n",
    "    },\n",
    "    'FineTuningDensenet121MultiTaskV2': {\n",
    "        'base_model': 'densenet121multitaskV2',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningDensenet121MultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.07242534468180122',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningDensenet121MultiTask': {\n",
    "        'base_model': 'densenet121multitask',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningDensenet121': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningDensenet121v1': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2', 'denseblock3', 'transition3']\n",
    "    },\n",
    "    'FineTuningDensenet121v2': {\n",
    "        'base_model': 'densenet121',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningDensenet121v1',\n",
    "        'layers_to_frozen': ['conv0', 'norm0', 'denseblock1', 'transition1', \n",
    "                             'denseblock2', 'transition2']\n",
    "    },\n",
    "    'PreVGG16': {\n",
    "        'base_model': 'vgg16',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['features.0', 'features.2', 'features.5', 'features.7', \n",
    "                             'features.10', 'features.12', 'features.14', 'features.17', \n",
    "                             'features.19', 'features.21', 'features.24', 'features.26', \n",
    "                             'features.28', 'classifier.0', 'classifier.3']\n",
    "    },\n",
    "    'PreResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "    },\n",
    "    'FineTuningResNet50': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50Attention': {\n",
    "        'base_model': 'ResNet50Attention',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50AttentionMultiTask': {\n",
    "        'base_model': 'ResNet50AttentionMultiTask',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': []\n",
    "    },    \n",
    "    'FineTuningResNet50AttentionMultiTaskV2': {\n",
    "        'base_model': 'ResNet50AttentionMultiTaskV2',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningResNet50AttentionMultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.07666666343915433',\n",
    "        'layers_to_frozen': []\n",
    "    },\n",
    "    'FineTuningResNet50v1': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "    },\n",
    "    'FineTuningResNet50v2': {\n",
    "        'base_model': 'resnet50',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': True,\n",
    "        'checkpoint_from': 'FineTuningResNet50v1',\n",
    "        'layers_to_frozen': ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "    },\n",
    "    'PreInceptionV3': {\n",
    "        'base_model': 'inception_v3',\n",
    "        'is_inception': True,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['AuxLogits.conv0', 'AuxLogits.conv1', 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', \n",
    "                             'Conv2d_2b_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', \n",
    "                             'Mixed_5b.branch1x1', 'Mixed_5b.branch3x3dbl_1', \n",
    "                             'Mixed_5b.branch3x3dbl_2', 'Mixed_5b.branch3x3dbl_3', 'Mixed_5b.branch5x5_1', \n",
    "                             'Mixed_5b.branch5x5_2', 'Mixed_5b.branch_pool', 'Mixed_5c.branch1x1', \n",
    "                             'Mixed_5c.branch3x3dbl_1', 'Mixed_5c.branch3x3dbl_2', 'Mixed_5c.branch3x3dbl_3', \n",
    "                             'Mixed_5c.branch5x5_1', 'Mixed_5c.branch5x5_2', 'Mixed_5c.branch_pool', \n",
    "                             'Mixed_5d.branch1x1', 'Mixed_5d.branch3x3dbl_1', 'Mixed_5d.branch3x3dbl_2', \n",
    "                             'Mixed_5d.branch3x3dbl_3', 'Mixed_5d.branch5x5_1', 'Mixed_5d.branch5x5_2', \n",
    "                             'Mixed_5d.branch_pool', 'Mixed_6a.branch3x3', 'Mixed_6a.branch3x3dbl_1', \n",
    "                             'Mixed_6a.branch3x3dbl_2', 'Mixed_6a.branch3x3dbl_3', 'Mixed_6b.branch1x1', \n",
    "                             'Mixed_6b.branch7x7_1', 'Mixed_6b.branch7x7_2', 'Mixed_6b.branch7x7_3', \n",
    "                             'Mixed_6b.branch7x7dbl_1', 'Mixed_6b.branch7x7dbl_2', 'Mixed_6b.branch7x7dbl_3', \n",
    "                             'Mixed_6b.branch7x7dbl_4', 'Mixed_6b.branch7x7dbl_5', 'Mixed_6b.branch_pool', \n",
    "                             'Mixed_6c.branch1x1', 'Mixed_6c.branch7x7_1', 'Mixed_6c.branch7x7_2', \n",
    "                             'Mixed_6c.branch7x7_3', 'Mixed_6c.branch7x7dbl_1', 'Mixed_6c.branch7x7dbl_2', \n",
    "                             'Mixed_6c.branch7x7dbl_3', 'Mixed_6c.branch7x7dbl_4', 'Mixed_6c.branch7x7dbl_5', \n",
    "                             'Mixed_6c.branch_pool', 'Mixed_6d.branch1x1', 'Mixed_6d.branch7x7_1', \n",
    "                             'Mixed_6d.branch7x7_2', 'Mixed_6d.branch7x7_3', 'Mixed_6d.branch7x7dbl_1', \n",
    "                             'Mixed_6d.branch7x7dbl_2', 'Mixed_6d.branch7x7dbl_3', 'Mixed_6d.branch7x7dbl_4', \n",
    "                             'Mixed_6d.branch7x7dbl_5', 'Mixed_6d.branch_pool', 'Mixed_6e.branch1x1', \n",
    "                             'Mixed_6e.branch7x7_1', 'Mixed_6e.branch7x7_2', 'Mixed_6e.branch7x7_3', \n",
    "                             'Mixed_6e.branch7x7dbl_1', 'Mixed_6e.branch7x7dbl_2', 'Mixed_6e.branch7x7dbl_3', \n",
    "                             'Mixed_6e.branch7x7dbl_4', 'Mixed_6e.branch7x7dbl_5', 'Mixed_6e.branch_pool', \n",
    "                             'Mixed_7a.branch3x3_1', 'Mixed_7a.branch3x3_2', 'Mixed_7a.branch7x7x3_1', \n",
    "                             'Mixed_7a.branch7x7x3_2', 'Mixed_7a.branch7x7x3_3', 'Mixed_7a.branch7x7x3_4', \n",
    "                             'Mixed_7b.branch1x1', 'Mixed_7b.branch3x3_1', 'Mixed_7b.branch3x3_2a', \n",
    "                             'Mixed_7b.branch3x3_2b', 'Mixed_7b.branch3x3dbl_1', 'Mixed_7b.branch3x3dbl_2', \n",
    "                             'Mixed_7b.branch3x3dbl_3a', 'Mixed_7b.branch3x3dbl_3b', 'Mixed_7b.branch_pool', \n",
    "                             'Mixed_7c.branch1x1', 'Mixed_7c.branch3x3_1', 'Mixed_7c.branch3x3_2a', \n",
    "                             'Mixed_7c.branch3x3_2b', 'Mixed_7c.branch3x3dbl_1', 'Mixed_7c.branch3x3dbl_2', \n",
    "                             'Mixed_7c.branch3x3dbl_3a', 'Mixed_7c.branch3x3dbl_3b', 'Mixed_7c.branch_pool']\n",
    "    },\n",
    "    'PreEfficientNetB7': {\n",
    "        'base_model': 'efficientnetb7',\n",
    "        'is_inception': False,\n",
    "        'pretrained': True,\n",
    "        'load_checkpoint': False,\n",
    "        'checkpoint_from': '',\n",
    "        'layers_to_frozen': ['_conv_stem', '_bn0', '_blocks', '_conv_head', '_bn1']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER_LIST = {\n",
    "    'DefaultAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.001,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'HalfLRAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.0005,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'DoubleWDAdam': {\n",
    "        'function': 'Adam',\n",
    "        'lr': 0.001,\n",
    "        'betas': (0.9, 0.999),\n",
    "        'eps': 1e-08,\n",
    "        'weight_decay': 0.0001,\n",
    "        'amsgrad': False\n",
    "    },\n",
    "    'SGDMomentum': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.1,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    },\n",
    "    'SGDMomentumV2': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.05,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    },\n",
    "    'SGDMomentumV3': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.1,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.005\n",
    "    },\n",
    "    'SGDMomentumV4': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.05,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.005\n",
    "    },\n",
    "    'SGDMomentumV5': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.03,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    },\n",
    "    'SGDMomentumV6': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.01,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    },\n",
    "    'SGDMomentumV7': {\n",
    "        'function': 'SGD',\n",
    "        'lr': 0.0075,\n",
    "        'weight_decay': 0,\n",
    "        'momentum': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "LOSS_LIST = {\n",
    "    'DefaultNLLLoss': {\n",
    "        'function': 'NLLLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultSmoothL1Loss': {\n",
    "        'function': 'SmoothL1Loss',\n",
    "        'size_average': None,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'DefaultCrossEntropyLoss': {\n",
    "        'function': 'CrossEntropyLoss',\n",
    "        'weight': None,\n",
    "        'size_average': None,\n",
    "        'ignore_index': -100,\n",
    "        'reduce': None,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "    'QuadraticKappa': {\n",
    "        'function': 'QuadraticKappa',\n",
    "        'n_classes': NUM_CLASSES\n",
    "    },\n",
    "    'WeightedMultiLabelLogLoss': {\n",
    "        'function': 'WeightedMultiLabelLogLoss',\n",
    "        'n_classes': NUM_CLASSES,\n",
    "        'weight': None\n",
    "    },\n",
    "    'WeightedMultiLabelFocalLogLoss': {\n",
    "        'function': 'WeightedMultiLabelFocalLogLoss',\n",
    "        'n_classes': NUM_CLASSES,\n",
    "        'weight': None,\n",
    "        'gamma': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "#DATASET_LIST = {\n",
    "#    'WLWW_4040_50100_6040': {\n",
    "#        'convert_BGR2RGB': False,\n",
    "#        'normalize_255': False,\n",
    "#        'channels': 3,\n",
    "#        'channels_first': True,\n",
    "#        'custom_function': None\n",
    "#    },\n",
    "#    'WLWW_4040': {\n",
    "#        'train_dir': DATA_DIR + '/numpy_array/stage_1_train_images_299',\n",
    "#        'val_dir': None,\n",
    "#        'test_dir': DATA_DIR + '/numpy_array/stage_1_train_images_299'\n",
    "#        'convert_BGR2RGB': False,\n",
    "#        'normalize_255': False,\n",
    "#        'channels': 3,\n",
    "#        'channels_first': True,\n",
    "#        'custom_function': None\n",
    "#    }\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)    \n",
    "\n",
    "# Detect if we have a GPU available\n",
    "cuda_list = ','.join(str(c) for c in CUDA_DEVICES)\n",
    "device = torch.device(\"cuda:{}\".format(cuda_list) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, img_folder, img_ext='png', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (dataframe): Dataframe with images ID.\n",
    "            y (dataframe): Dataframe with labels annotations.\n",
    "            img_folder (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.img_folder = img_folder\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "        \n",
    "       #image = np.load(img_name).astype('uint8')\n",
    "        image = np.load(img_name)\n",
    "        \n",
    "        label = self.y.iloc[idx].to_numpy()\n",
    "        \n",
    "        if self.transform:\n",
    "       \n",
    "           image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "        return (image,label)\n",
    "    \n",
    "# class CustomDataset_v2(Dataset):\n",
    "\n",
    "#     def __init__(self, X, y, img_folder, img_ext='png', transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             X (dataframe): Dataframe with images ID.\n",
    "#             y (dataframe): Dataframe with labels annotations.\n",
    "#             img_folder (string): Directory with all the images.\n",
    "#             transform (callable, optional): Optional transform to be applied\n",
    "#                 on a sample.\n",
    "#         \"\"\"\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.img_folder = img_folder\n",
    "#         self.img_ext = img_ext\n",
    "#         self.transform = transform\n",
    "#         self.hu_min = -1024 # Min value of Hounsfield scale\n",
    "#         self.hu_max = 3071 # Max value of Hounsfield scale\n",
    "#         self.hu_delta = self.hu_max - self.hu_min # Just to save calculation\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.img_folder, self.X.iloc[idx, 0] + '.' + self.img_ext)\n",
    "#         #image = np.load(img_name).astype('uint8')\n",
    "#         image = np.load(img_name)\n",
    "        \n",
    "#         image = image[:,:,[2]]\n",
    "#         image = np.repeat(image, 3, axis=2)\n",
    "        \n",
    "#         label = self.y.iloc[idx].to_numpy()\n",
    "        \n",
    "#         if self.transform:\n",
    "        \n",
    "#             image = self.transform(TF.to_pil_image(image))\n",
    "\n",
    "#         return (image,label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN_LABELS)\n",
    "data = data.loc[~data.id.isin(BLACK_LIST_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2478454668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    data = data.sample(frac = SAMPLE_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f246bcfbcc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[LABEL_COLUMN].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc Classes Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39568065, 13.57933227,  1.18242981,  1.62972715,  1.19711282,\n",
       "        0.90546156])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distrib_freq = data[LABEL_COLUMN].sum().to_numpy()\n",
    "w_classes = distrib_freq.sum() / (NUM_CLASSES * distrib_freq)\n",
    "w_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Wrong Loss Function Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in LOSSES:\n",
    "    if 'weight' in LOSS_LIST[l]:\n",
    "        LOSS_LIST[l]['weight'] = torch.from_numpy(w_classes).to(device)\n",
    "    else:\n",
    "        raise Exception('You are trying to set weight in a loss function without weight parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(LABEL_COLUMN + ['z_min_max'], axis=1)\n",
    "y = data[LABEL_COLUMN + ['z_min_max']]\n",
    "\n",
    "# Criando o dataframe de treine e teste com base no dataframe anteriormente criado\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = TEST_SPLIT, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>z_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   any  epidural  intraparenchymal  intraventricular  subarachnoid  subdural  \\\n",
       "0    0         0                 0                 0             0         0   \n",
       "1    0         0                 0                 0             0         0   \n",
       "2    0         0                 0                 0             0         0   \n",
       "3    0         0                 0                 0             0         0   \n",
       "4    0         0                 0                 0             0         0   \n",
       "\n",
       "   z_min_max  \n",
       "0   0.258064  \n",
       "1   0.111102  \n",
       "2   0.054054  \n",
       "3   0.290449  \n",
       "4   0.914286  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf = transforms.Compose([\n",
    "    transforms.RandomRotation((0,360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X=X_train, \n",
    "                              y=y_train, \n",
    "                              img_folder=TRAIN_DIR,\n",
    "                              img_ext=IMAGE_FORMAT, \n",
    "                              transform=train_transf)\n",
    "\n",
    "test_dataset = CustomDataset(X=X_test, \n",
    "                             y=y_test, \n",
    "                             img_folder=TEST_DIR, \n",
    "                             img_ext=IMAGE_FORMAT,\n",
    "                             transform=test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garregando os dados\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBestModel(model_name):\n",
    "    device = torch.device(\"cuda:{}\".format(cuda_list) if torch.cuda.is_available() else \"cpu\")\n",
    "    # Get lastest model file\n",
    "    list_of_files = glob.glob(MODEL_DIR + f'/*{model_name}*.pt') # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f'Loading model {latest_file}')\n",
    "    model = torch.load(latest_file, map_location=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name, num_classes):\n",
    "    \n",
    "    model_parameters = MODEL_LIST[model_name]\n",
    "    \n",
    "    if model_parameters['load_checkpoint']:\n",
    "        \n",
    "        model = loadBestModel(model_parameters['checkpoint_from'])\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        if model_parameters['base_model']=='densenet121':\n",
    "            \n",
    "            model = densenet121(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier = nn.Linear(1024, num_classes)   \n",
    "                \n",
    "        if model_parameters['base_model']=='densenet121multitask':\n",
    "            \n",
    "            model = densenet121multitask(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier = nn.Linear(1024, num_classes)   \n",
    "            model.aux_classifier = nn.Linear(1024, 1)   \n",
    "                \n",
    "        if model_parameters['base_model']=='vgg16':\n",
    "            \n",
    "            model = vgg16(pretrained=model_parameters['pretrained'])\n",
    "            model.classifier[6] = nn.Linear(4096, num_classes) \n",
    "        \n",
    "        if model_parameters['base_model']=='resnet50':\n",
    "            \n",
    "            model = resnet50(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    " \n",
    "        if model_parameters['base_model']=='ResNet50Attention':\n",
    "            model = ResNet50Attention(num_classes, \n",
    "                                      attention=True, \n",
    "                                      pretrained=model_parameters['pretrained'])\n",
    "        if model_parameters['base_model']=='ResNet50AttentionMultiTask':\n",
    "            model = ResNet50AttentionMultiTask(num_classes, \n",
    "                                      attention=True, \n",
    "                                      pretrained=model_parameters['pretrained'])\n",
    "        if model_parameters['base_model']=='inception_v3':\n",
    "            \n",
    "            model = inception_v3(pretrained=model_parameters['pretrained'])\n",
    "            model.fc = nn.Linear(2048, num_classes) \n",
    "            model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            \n",
    "        elif model_parameters['base_model']=='efficientnetb7':\n",
    "            \n",
    "            model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "            model._fc = nn.Linear(2560, NUM_CLASSES) \n",
    "        if is_cuda & (torch.cuda.device_count() > 1) & (not model_parameters['is_inception']):\n",
    "            if not CUDA_DEVICES:\n",
    "                print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "                model = nn.DataParallel(model) # When load checkpoint, the DataParallel is already in the model.\n",
    "            else:\n",
    "                print(\"Let's use\", CUDA_DEVICES, \"GPUs!\")\n",
    "                model = nn.DataParallel(model, device_ids = CUDA_DEVICES) # When load checkpoint, the DataParallel is already in the model.\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        for l in model_parameters['layers_to_frozen']:\n",
    "            if l in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    if is_cuda:\n",
    "        model = model.to(device)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizer(optimizer_name, model):\n",
    "\n",
    "    params_to_update = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "    \n",
    "        if param.requires_grad == True:\n",
    "        \n",
    "            params_to_update.append(param)\n",
    "            \n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    opt_parameters = OPTIMIZER_LIST[optimizer_name]\n",
    "\n",
    "    if opt_parameters['function'] == 'Adam':\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params_to_update, \n",
    "                                     lr = opt_parameters['lr'],\n",
    "                                     betas = opt_parameters['betas'],\n",
    "                                     eps = opt_parameters['eps'],\n",
    "                                     weight_decay = opt_parameters['weight_decay'],\n",
    "                                     amsgrad = opt_parameters['amsgrad']\n",
    "                                    )\n",
    "    elif opt_parameters['function'] == 'SGD':\n",
    "        \n",
    "        optimizer = torch.optim.SGD(params_to_update, \n",
    "                                     lr = opt_parameters['lr'],\n",
    "                                     weight_decay = opt_parameters['weight_decay'],\n",
    "                                     momentum = opt_parameters['momentum']\n",
    "                                    )\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossFunction(loss_nme):\n",
    "    \n",
    "    loss_parameters = LOSS_LIST[loss_nme]\n",
    "\n",
    "    if loss_parameters['function'] == 'SmoothL1Loss':\n",
    "        criterion = nn.SmoothL1Loss(\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'CrossEntropyLoss':\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'NLLLoss':\n",
    "\n",
    "        criterion = nn.NLLLoss(\n",
    "            weight = loss_parameters['weight'],\n",
    "            size_average = loss_parameters['size_average'],\n",
    "            ignore_index = loss_parameters['ignore_index'],\n",
    "            reduce = loss_parameters['reduce'],\n",
    "            reduction = loss_parameters['reduction']\n",
    "        )\n",
    "\n",
    "    elif loss_parameters['function'] == 'QuadraticKappa':\n",
    "        criterion = QuadraticKappa(\n",
    "            n_classes = loss_parameters['n_classes']\n",
    "        )\n",
    "        \n",
    "    elif loss_parameters['function'] == 'WeightedMultiLabelLogLoss':\n",
    "\n",
    "        criterion = WeightedMultiLabelLogLoss(\n",
    "            n_classes = loss_parameters['n_classes'],\n",
    "            weight = loss_parameters['weight']\n",
    "        )\n",
    "    elif loss_parameters['function'] == 'WeightedMultiLabelFocalLogLoss':\n",
    "\n",
    "        criterion = WeightedMultiLabelFocalLogLoss(\n",
    "            n_classes = loss_parameters['n_classes'],\n",
    "            weight = loss_parameters['weight'],\n",
    "            gamma = loss_parameters['gamma']\n",
    "        )\n",
    "        \n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def onehot(labels, num_classes):\n",
    "    return torch.zeros(len(labels), num_classes).scatter_(1, labels.unsqueeze(1).cpu(), 1.).cuda()\n",
    "\n",
    "def train_model(model, model_name, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    best_loss = 999\n",
    "    criterion2 = nn.L1Loss()\n",
    "    \n",
    "    print(model_name)\n",
    "    print('-' * 100)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        epoch_since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            #running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        \n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        aux_outputs = torch.sigmoid(aux_outputs)\n",
    "                        \n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                        \n",
    "                    elif not is_inception and phase == 'train':\n",
    "                        outputs1, outputs2 = model(inputs)\n",
    "                        outputs1 = torch.sigmoid(outputs1)\n",
    "                        \n",
    "                        loss1 = criterion(outputs1, labels[:,:-1])\n",
    "                        loss2 = criterion2(outputs2, labels[:,-1].float())\n",
    "                        \n",
    "                        loss = loss1 + (loss2 * 0.15)\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        outputs1, outputs2 = model(inputs)\n",
    "                        outputs = torch.sigmoid(outputs1)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels[:,:-1])\n",
    "                        \n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            #epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            #lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # Write loss into Tensorboard\n",
    "            tensorboard.add_scalar('Loss {}'.format(phase), epoch_loss, epoch)\n",
    "            #tensorboard.add_scalar('Acc {}'.format(phase), epoch_acc, epoch)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Saving the best model...')\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model, MODEL_DIR + '/' + model_name + '_imgsize' + str(INPUT_SIZE) + '_loss' + str(best_loss) + '.pt')\n",
    "            \n",
    "        epoch_time_elapsed = time.time() - epoch_since\n",
    "        print('Epoch time elapsed: {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('')\n",
    "\n",
    "    # load best model weights\n",
    "    model = loadBestModel(model_name)\n",
    "    return model, best_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model /srv/app/data/models/FineTuningDensenet121MultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss_imgsize299_loss0.07242534468180122.pt\n",
      "\t module.features.conv0.weight\n",
      "\t module.features.norm0.weight\n",
      "\t module.features.norm0.bias\n",
      "\t module.features.denseblock1.denselayer1.norm1.weight\n",
      "\t module.features.denseblock1.denselayer1.norm1.bias\n",
      "\t module.features.denseblock1.denselayer1.conv1.weight\n",
      "\t module.features.denseblock1.denselayer1.norm2.weight\n",
      "\t module.features.denseblock1.denselayer1.norm2.bias\n",
      "\t module.features.denseblock1.denselayer1.conv2.weight\n",
      "\t module.features.denseblock1.denselayer2.norm1.weight\n",
      "\t module.features.denseblock1.denselayer2.norm1.bias\n",
      "\t module.features.denseblock1.denselayer2.conv1.weight\n",
      "\t module.features.denseblock1.denselayer2.norm2.weight\n",
      "\t module.features.denseblock1.denselayer2.norm2.bias\n",
      "\t module.features.denseblock1.denselayer2.conv2.weight\n",
      "\t module.features.denseblock1.denselayer3.norm1.weight\n",
      "\t module.features.denseblock1.denselayer3.norm1.bias\n",
      "\t module.features.denseblock1.denselayer3.conv1.weight\n",
      "\t module.features.denseblock1.denselayer3.norm2.weight\n",
      "\t module.features.denseblock1.denselayer3.norm2.bias\n",
      "\t module.features.denseblock1.denselayer3.conv2.weight\n",
      "\t module.features.denseblock1.denselayer4.norm1.weight\n",
      "\t module.features.denseblock1.denselayer4.norm1.bias\n",
      "\t module.features.denseblock1.denselayer4.conv1.weight\n",
      "\t module.features.denseblock1.denselayer4.norm2.weight\n",
      "\t module.features.denseblock1.denselayer4.norm2.bias\n",
      "\t module.features.denseblock1.denselayer4.conv2.weight\n",
      "\t module.features.denseblock1.denselayer5.norm1.weight\n",
      "\t module.features.denseblock1.denselayer5.norm1.bias\n",
      "\t module.features.denseblock1.denselayer5.conv1.weight\n",
      "\t module.features.denseblock1.denselayer5.norm2.weight\n",
      "\t module.features.denseblock1.denselayer5.norm2.bias\n",
      "\t module.features.denseblock1.denselayer5.conv2.weight\n",
      "\t module.features.denseblock1.denselayer6.norm1.weight\n",
      "\t module.features.denseblock1.denselayer6.norm1.bias\n",
      "\t module.features.denseblock1.denselayer6.conv1.weight\n",
      "\t module.features.denseblock1.denselayer6.norm2.weight\n",
      "\t module.features.denseblock1.denselayer6.norm2.bias\n",
      "\t module.features.denseblock1.denselayer6.conv2.weight\n",
      "\t module.features.transition1.norm.weight\n",
      "\t module.features.transition1.norm.bias\n",
      "\t module.features.transition1.conv.weight\n",
      "\t module.features.denseblock2.denselayer1.norm1.weight\n",
      "\t module.features.denseblock2.denselayer1.norm1.bias\n",
      "\t module.features.denseblock2.denselayer1.conv1.weight\n",
      "\t module.features.denseblock2.denselayer1.norm2.weight\n",
      "\t module.features.denseblock2.denselayer1.norm2.bias\n",
      "\t module.features.denseblock2.denselayer1.conv2.weight\n",
      "\t module.features.denseblock2.denselayer2.norm1.weight\n",
      "\t module.features.denseblock2.denselayer2.norm1.bias\n",
      "\t module.features.denseblock2.denselayer2.conv1.weight\n",
      "\t module.features.denseblock2.denselayer2.norm2.weight\n",
      "\t module.features.denseblock2.denselayer2.norm2.bias\n",
      "\t module.features.denseblock2.denselayer2.conv2.weight\n",
      "\t module.features.denseblock2.denselayer3.norm1.weight\n",
      "\t module.features.denseblock2.denselayer3.norm1.bias\n",
      "\t module.features.denseblock2.denselayer3.conv1.weight\n",
      "\t module.features.denseblock2.denselayer3.norm2.weight\n",
      "\t module.features.denseblock2.denselayer3.norm2.bias\n",
      "\t module.features.denseblock2.denselayer3.conv2.weight\n",
      "\t module.features.denseblock2.denselayer4.norm1.weight\n",
      "\t module.features.denseblock2.denselayer4.norm1.bias\n",
      "\t module.features.denseblock2.denselayer4.conv1.weight\n",
      "\t module.features.denseblock2.denselayer4.norm2.weight\n",
      "\t module.features.denseblock2.denselayer4.norm2.bias\n",
      "\t module.features.denseblock2.denselayer4.conv2.weight\n",
      "\t module.features.denseblock2.denselayer5.norm1.weight\n",
      "\t module.features.denseblock2.denselayer5.norm1.bias\n",
      "\t module.features.denseblock2.denselayer5.conv1.weight\n",
      "\t module.features.denseblock2.denselayer5.norm2.weight\n",
      "\t module.features.denseblock2.denselayer5.norm2.bias\n",
      "\t module.features.denseblock2.denselayer5.conv2.weight\n",
      "\t module.features.denseblock2.denselayer6.norm1.weight\n",
      "\t module.features.denseblock2.denselayer6.norm1.bias\n",
      "\t module.features.denseblock2.denselayer6.conv1.weight\n",
      "\t module.features.denseblock2.denselayer6.norm2.weight\n",
      "\t module.features.denseblock2.denselayer6.norm2.bias\n",
      "\t module.features.denseblock2.denselayer6.conv2.weight\n",
      "\t module.features.denseblock2.denselayer7.norm1.weight\n",
      "\t module.features.denseblock2.denselayer7.norm1.bias\n",
      "\t module.features.denseblock2.denselayer7.conv1.weight\n",
      "\t module.features.denseblock2.denselayer7.norm2.weight\n",
      "\t module.features.denseblock2.denselayer7.norm2.bias\n",
      "\t module.features.denseblock2.denselayer7.conv2.weight\n",
      "\t module.features.denseblock2.denselayer8.norm1.weight\n",
      "\t module.features.denseblock2.denselayer8.norm1.bias\n",
      "\t module.features.denseblock2.denselayer8.conv1.weight\n",
      "\t module.features.denseblock2.denselayer8.norm2.weight\n",
      "\t module.features.denseblock2.denselayer8.norm2.bias\n",
      "\t module.features.denseblock2.denselayer8.conv2.weight\n",
      "\t module.features.denseblock2.denselayer9.norm1.weight\n",
      "\t module.features.denseblock2.denselayer9.norm1.bias\n",
      "\t module.features.denseblock2.denselayer9.conv1.weight\n",
      "\t module.features.denseblock2.denselayer9.norm2.weight\n",
      "\t module.features.denseblock2.denselayer9.norm2.bias\n",
      "\t module.features.denseblock2.denselayer9.conv2.weight\n",
      "\t module.features.denseblock2.denselayer10.norm1.weight\n",
      "\t module.features.denseblock2.denselayer10.norm1.bias\n",
      "\t module.features.denseblock2.denselayer10.conv1.weight\n",
      "\t module.features.denseblock2.denselayer10.norm2.weight\n",
      "\t module.features.denseblock2.denselayer10.norm2.bias\n",
      "\t module.features.denseblock2.denselayer10.conv2.weight\n",
      "\t module.features.denseblock2.denselayer11.norm1.weight\n",
      "\t module.features.denseblock2.denselayer11.norm1.bias\n",
      "\t module.features.denseblock2.denselayer11.conv1.weight\n",
      "\t module.features.denseblock2.denselayer11.norm2.weight\n",
      "\t module.features.denseblock2.denselayer11.norm2.bias\n",
      "\t module.features.denseblock2.denselayer11.conv2.weight\n",
      "\t module.features.denseblock2.denselayer12.norm1.weight\n",
      "\t module.features.denseblock2.denselayer12.norm1.bias\n",
      "\t module.features.denseblock2.denselayer12.conv1.weight\n",
      "\t module.features.denseblock2.denselayer12.norm2.weight\n",
      "\t module.features.denseblock2.denselayer12.norm2.bias\n",
      "\t module.features.denseblock2.denselayer12.conv2.weight\n",
      "\t module.features.transition2.norm.weight\n",
      "\t module.features.transition2.norm.bias\n",
      "\t module.features.transition2.conv.weight\n",
      "\t module.features.denseblock3.denselayer1.norm1.weight\n",
      "\t module.features.denseblock3.denselayer1.norm1.bias\n",
      "\t module.features.denseblock3.denselayer1.conv1.weight\n",
      "\t module.features.denseblock3.denselayer1.norm2.weight\n",
      "\t module.features.denseblock3.denselayer1.norm2.bias\n",
      "\t module.features.denseblock3.denselayer1.conv2.weight\n",
      "\t module.features.denseblock3.denselayer2.norm1.weight\n",
      "\t module.features.denseblock3.denselayer2.norm1.bias\n",
      "\t module.features.denseblock3.denselayer2.conv1.weight\n",
      "\t module.features.denseblock3.denselayer2.norm2.weight\n",
      "\t module.features.denseblock3.denselayer2.norm2.bias\n",
      "\t module.features.denseblock3.denselayer2.conv2.weight\n",
      "\t module.features.denseblock3.denselayer3.norm1.weight\n",
      "\t module.features.denseblock3.denselayer3.norm1.bias\n",
      "\t module.features.denseblock3.denselayer3.conv1.weight\n",
      "\t module.features.denseblock3.denselayer3.norm2.weight\n",
      "\t module.features.denseblock3.denselayer3.norm2.bias\n",
      "\t module.features.denseblock3.denselayer3.conv2.weight\n",
      "\t module.features.denseblock3.denselayer4.norm1.weight\n",
      "\t module.features.denseblock3.denselayer4.norm1.bias\n",
      "\t module.features.denseblock3.denselayer4.conv1.weight\n",
      "\t module.features.denseblock3.denselayer4.norm2.weight\n",
      "\t module.features.denseblock3.denselayer4.norm2.bias\n",
      "\t module.features.denseblock3.denselayer4.conv2.weight\n",
      "\t module.features.denseblock3.denselayer5.norm1.weight\n",
      "\t module.features.denseblock3.denselayer5.norm1.bias\n",
      "\t module.features.denseblock3.denselayer5.conv1.weight\n",
      "\t module.features.denseblock3.denselayer5.norm2.weight\n",
      "\t module.features.denseblock3.denselayer5.norm2.bias\n",
      "\t module.features.denseblock3.denselayer5.conv2.weight\n",
      "\t module.features.denseblock3.denselayer6.norm1.weight\n",
      "\t module.features.denseblock3.denselayer6.norm1.bias\n",
      "\t module.features.denseblock3.denselayer6.conv1.weight\n",
      "\t module.features.denseblock3.denselayer6.norm2.weight\n",
      "\t module.features.denseblock3.denselayer6.norm2.bias\n",
      "\t module.features.denseblock3.denselayer6.conv2.weight\n",
      "\t module.features.denseblock3.denselayer7.norm1.weight\n",
      "\t module.features.denseblock3.denselayer7.norm1.bias\n",
      "\t module.features.denseblock3.denselayer7.conv1.weight\n",
      "\t module.features.denseblock3.denselayer7.norm2.weight\n",
      "\t module.features.denseblock3.denselayer7.norm2.bias\n",
      "\t module.features.denseblock3.denselayer7.conv2.weight\n",
      "\t module.features.denseblock3.denselayer8.norm1.weight\n",
      "\t module.features.denseblock3.denselayer8.norm1.bias\n",
      "\t module.features.denseblock3.denselayer8.conv1.weight\n",
      "\t module.features.denseblock3.denselayer8.norm2.weight\n",
      "\t module.features.denseblock3.denselayer8.norm2.bias\n",
      "\t module.features.denseblock3.denselayer8.conv2.weight\n",
      "\t module.features.denseblock3.denselayer9.norm1.weight\n",
      "\t module.features.denseblock3.denselayer9.norm1.bias\n",
      "\t module.features.denseblock3.denselayer9.conv1.weight\n",
      "\t module.features.denseblock3.denselayer9.norm2.weight\n",
      "\t module.features.denseblock3.denselayer9.norm2.bias\n",
      "\t module.features.denseblock3.denselayer9.conv2.weight\n",
      "\t module.features.denseblock3.denselayer10.norm1.weight\n",
      "\t module.features.denseblock3.denselayer10.norm1.bias\n",
      "\t module.features.denseblock3.denselayer10.conv1.weight\n",
      "\t module.features.denseblock3.denselayer10.norm2.weight\n",
      "\t module.features.denseblock3.denselayer10.norm2.bias\n",
      "\t module.features.denseblock3.denselayer10.conv2.weight\n",
      "\t module.features.denseblock3.denselayer11.norm1.weight\n",
      "\t module.features.denseblock3.denselayer11.norm1.bias\n",
      "\t module.features.denseblock3.denselayer11.conv1.weight\n",
      "\t module.features.denseblock3.denselayer11.norm2.weight\n",
      "\t module.features.denseblock3.denselayer11.norm2.bias\n",
      "\t module.features.denseblock3.denselayer11.conv2.weight\n",
      "\t module.features.denseblock3.denselayer12.norm1.weight\n",
      "\t module.features.denseblock3.denselayer12.norm1.bias\n",
      "\t module.features.denseblock3.denselayer12.conv1.weight\n",
      "\t module.features.denseblock3.denselayer12.norm2.weight\n",
      "\t module.features.denseblock3.denselayer12.norm2.bias\n",
      "\t module.features.denseblock3.denselayer12.conv2.weight\n",
      "\t module.features.denseblock3.denselayer13.norm1.weight\n",
      "\t module.features.denseblock3.denselayer13.norm1.bias\n",
      "\t module.features.denseblock3.denselayer13.conv1.weight\n",
      "\t module.features.denseblock3.denselayer13.norm2.weight\n",
      "\t module.features.denseblock3.denselayer13.norm2.bias\n",
      "\t module.features.denseblock3.denselayer13.conv2.weight\n",
      "\t module.features.denseblock3.denselayer14.norm1.weight\n",
      "\t module.features.denseblock3.denselayer14.norm1.bias\n",
      "\t module.features.denseblock3.denselayer14.conv1.weight\n",
      "\t module.features.denseblock3.denselayer14.norm2.weight\n",
      "\t module.features.denseblock3.denselayer14.norm2.bias\n",
      "\t module.features.denseblock3.denselayer14.conv2.weight\n",
      "\t module.features.denseblock3.denselayer15.norm1.weight\n",
      "\t module.features.denseblock3.denselayer15.norm1.bias\n",
      "\t module.features.denseblock3.denselayer15.conv1.weight\n",
      "\t module.features.denseblock3.denselayer15.norm2.weight\n",
      "\t module.features.denseblock3.denselayer15.norm2.bias\n",
      "\t module.features.denseblock3.denselayer15.conv2.weight\n",
      "\t module.features.denseblock3.denselayer16.norm1.weight\n",
      "\t module.features.denseblock3.denselayer16.norm1.bias\n",
      "\t module.features.denseblock3.denselayer16.conv1.weight\n",
      "\t module.features.denseblock3.denselayer16.norm2.weight\n",
      "\t module.features.denseblock3.denselayer16.norm2.bias\n",
      "\t module.features.denseblock3.denselayer16.conv2.weight\n",
      "\t module.features.denseblock3.denselayer17.norm1.weight\n",
      "\t module.features.denseblock3.denselayer17.norm1.bias\n",
      "\t module.features.denseblock3.denselayer17.conv1.weight\n",
      "\t module.features.denseblock3.denselayer17.norm2.weight\n",
      "\t module.features.denseblock3.denselayer17.norm2.bias\n",
      "\t module.features.denseblock3.denselayer17.conv2.weight\n",
      "\t module.features.denseblock3.denselayer18.norm1.weight\n",
      "\t module.features.denseblock3.denselayer18.norm1.bias\n",
      "\t module.features.denseblock3.denselayer18.conv1.weight\n",
      "\t module.features.denseblock3.denselayer18.norm2.weight\n",
      "\t module.features.denseblock3.denselayer18.norm2.bias\n",
      "\t module.features.denseblock3.denselayer18.conv2.weight\n",
      "\t module.features.denseblock3.denselayer19.norm1.weight\n",
      "\t module.features.denseblock3.denselayer19.norm1.bias\n",
      "\t module.features.denseblock3.denselayer19.conv1.weight\n",
      "\t module.features.denseblock3.denselayer19.norm2.weight\n",
      "\t module.features.denseblock3.denselayer19.norm2.bias\n",
      "\t module.features.denseblock3.denselayer19.conv2.weight\n",
      "\t module.features.denseblock3.denselayer20.norm1.weight\n",
      "\t module.features.denseblock3.denselayer20.norm1.bias\n",
      "\t module.features.denseblock3.denselayer20.conv1.weight\n",
      "\t module.features.denseblock3.denselayer20.norm2.weight\n",
      "\t module.features.denseblock3.denselayer20.norm2.bias\n",
      "\t module.features.denseblock3.denselayer20.conv2.weight\n",
      "\t module.features.denseblock3.denselayer21.norm1.weight\n",
      "\t module.features.denseblock3.denselayer21.norm1.bias\n",
      "\t module.features.denseblock3.denselayer21.conv1.weight\n",
      "\t module.features.denseblock3.denselayer21.norm2.weight\n",
      "\t module.features.denseblock3.denselayer21.norm2.bias\n",
      "\t module.features.denseblock3.denselayer21.conv2.weight\n",
      "\t module.features.denseblock3.denselayer22.norm1.weight\n",
      "\t module.features.denseblock3.denselayer22.norm1.bias\n",
      "\t module.features.denseblock3.denselayer22.conv1.weight\n",
      "\t module.features.denseblock3.denselayer22.norm2.weight\n",
      "\t module.features.denseblock3.denselayer22.norm2.bias\n",
      "\t module.features.denseblock3.denselayer22.conv2.weight\n",
      "\t module.features.denseblock3.denselayer23.norm1.weight\n",
      "\t module.features.denseblock3.denselayer23.norm1.bias\n",
      "\t module.features.denseblock3.denselayer23.conv1.weight\n",
      "\t module.features.denseblock3.denselayer23.norm2.weight\n",
      "\t module.features.denseblock3.denselayer23.norm2.bias\n",
      "\t module.features.denseblock3.denselayer23.conv2.weight\n",
      "\t module.features.denseblock3.denselayer24.norm1.weight\n",
      "\t module.features.denseblock3.denselayer24.norm1.bias\n",
      "\t module.features.denseblock3.denselayer24.conv1.weight\n",
      "\t module.features.denseblock3.denselayer24.norm2.weight\n",
      "\t module.features.denseblock3.denselayer24.norm2.bias\n",
      "\t module.features.denseblock3.denselayer24.conv2.weight\n",
      "\t module.features.transition3.norm.weight\n",
      "\t module.features.transition3.norm.bias\n",
      "\t module.features.transition3.conv.weight\n",
      "\t module.features.denseblock4.denselayer1.norm1.weight\n",
      "\t module.features.denseblock4.denselayer1.norm1.bias\n",
      "\t module.features.denseblock4.denselayer1.conv1.weight\n",
      "\t module.features.denseblock4.denselayer1.norm2.weight\n",
      "\t module.features.denseblock4.denselayer1.norm2.bias\n",
      "\t module.features.denseblock4.denselayer1.conv2.weight\n",
      "\t module.features.denseblock4.denselayer2.norm1.weight\n",
      "\t module.features.denseblock4.denselayer2.norm1.bias\n",
      "\t module.features.denseblock4.denselayer2.conv1.weight\n",
      "\t module.features.denseblock4.denselayer2.norm2.weight\n",
      "\t module.features.denseblock4.denselayer2.norm2.bias\n",
      "\t module.features.denseblock4.denselayer2.conv2.weight\n",
      "\t module.features.denseblock4.denselayer3.norm1.weight\n",
      "\t module.features.denseblock4.denselayer3.norm1.bias\n",
      "\t module.features.denseblock4.denselayer3.conv1.weight\n",
      "\t module.features.denseblock4.denselayer3.norm2.weight\n",
      "\t module.features.denseblock4.denselayer3.norm2.bias\n",
      "\t module.features.denseblock4.denselayer3.conv2.weight\n",
      "\t module.features.denseblock4.denselayer4.norm1.weight\n",
      "\t module.features.denseblock4.denselayer4.norm1.bias\n",
      "\t module.features.denseblock4.denselayer4.conv1.weight\n",
      "\t module.features.denseblock4.denselayer4.norm2.weight\n",
      "\t module.features.denseblock4.denselayer4.norm2.bias\n",
      "\t module.features.denseblock4.denselayer4.conv2.weight\n",
      "\t module.features.denseblock4.denselayer5.norm1.weight\n",
      "\t module.features.denseblock4.denselayer5.norm1.bias\n",
      "\t module.features.denseblock4.denselayer5.conv1.weight\n",
      "\t module.features.denseblock4.denselayer5.norm2.weight\n",
      "\t module.features.denseblock4.denselayer5.norm2.bias\n",
      "\t module.features.denseblock4.denselayer5.conv2.weight\n",
      "\t module.features.denseblock4.denselayer6.norm1.weight\n",
      "\t module.features.denseblock4.denselayer6.norm1.bias\n",
      "\t module.features.denseblock4.denselayer6.conv1.weight\n",
      "\t module.features.denseblock4.denselayer6.norm2.weight\n",
      "\t module.features.denseblock4.denselayer6.norm2.bias\n",
      "\t module.features.denseblock4.denselayer6.conv2.weight\n",
      "\t module.features.denseblock4.denselayer7.norm1.weight\n",
      "\t module.features.denseblock4.denselayer7.norm1.bias\n",
      "\t module.features.denseblock4.denselayer7.conv1.weight\n",
      "\t module.features.denseblock4.denselayer7.norm2.weight\n",
      "\t module.features.denseblock4.denselayer7.norm2.bias\n",
      "\t module.features.denseblock4.denselayer7.conv2.weight\n",
      "\t module.features.denseblock4.denselayer8.norm1.weight\n",
      "\t module.features.denseblock4.denselayer8.norm1.bias\n",
      "\t module.features.denseblock4.denselayer8.conv1.weight\n",
      "\t module.features.denseblock4.denselayer8.norm2.weight\n",
      "\t module.features.denseblock4.denselayer8.norm2.bias\n",
      "\t module.features.denseblock4.denselayer8.conv2.weight\n",
      "\t module.features.denseblock4.denselayer9.norm1.weight\n",
      "\t module.features.denseblock4.denselayer9.norm1.bias\n",
      "\t module.features.denseblock4.denselayer9.conv1.weight\n",
      "\t module.features.denseblock4.denselayer9.norm2.weight\n",
      "\t module.features.denseblock4.denselayer9.norm2.bias\n",
      "\t module.features.denseblock4.denselayer9.conv2.weight\n",
      "\t module.features.denseblock4.denselayer10.norm1.weight\n",
      "\t module.features.denseblock4.denselayer10.norm1.bias\n",
      "\t module.features.denseblock4.denselayer10.conv1.weight\n",
      "\t module.features.denseblock4.denselayer10.norm2.weight\n",
      "\t module.features.denseblock4.denselayer10.norm2.bias\n",
      "\t module.features.denseblock4.denselayer10.conv2.weight\n",
      "\t module.features.denseblock4.denselayer11.norm1.weight\n",
      "\t module.features.denseblock4.denselayer11.norm1.bias\n",
      "\t module.features.denseblock4.denselayer11.conv1.weight\n",
      "\t module.features.denseblock4.denselayer11.norm2.weight\n",
      "\t module.features.denseblock4.denselayer11.norm2.bias\n",
      "\t module.features.denseblock4.denselayer11.conv2.weight\n",
      "\t module.features.denseblock4.denselayer12.norm1.weight\n",
      "\t module.features.denseblock4.denselayer12.norm1.bias\n",
      "\t module.features.denseblock4.denselayer12.conv1.weight\n",
      "\t module.features.denseblock4.denselayer12.norm2.weight\n",
      "\t module.features.denseblock4.denselayer12.norm2.bias\n",
      "\t module.features.denseblock4.denselayer12.conv2.weight\n",
      "\t module.features.denseblock4.denselayer13.norm1.weight\n",
      "\t module.features.denseblock4.denselayer13.norm1.bias\n",
      "\t module.features.denseblock4.denselayer13.conv1.weight\n",
      "\t module.features.denseblock4.denselayer13.norm2.weight\n",
      "\t module.features.denseblock4.denselayer13.norm2.bias\n",
      "\t module.features.denseblock4.denselayer13.conv2.weight\n",
      "\t module.features.denseblock4.denselayer14.norm1.weight\n",
      "\t module.features.denseblock4.denselayer14.norm1.bias\n",
      "\t module.features.denseblock4.denselayer14.conv1.weight\n",
      "\t module.features.denseblock4.denselayer14.norm2.weight\n",
      "\t module.features.denseblock4.denselayer14.norm2.bias\n",
      "\t module.features.denseblock4.denselayer14.conv2.weight\n",
      "\t module.features.denseblock4.denselayer15.norm1.weight\n",
      "\t module.features.denseblock4.denselayer15.norm1.bias\n",
      "\t module.features.denseblock4.denselayer15.conv1.weight\n",
      "\t module.features.denseblock4.denselayer15.norm2.weight\n",
      "\t module.features.denseblock4.denselayer15.norm2.bias\n",
      "\t module.features.denseblock4.denselayer15.conv2.weight\n",
      "\t module.features.denseblock4.denselayer16.norm1.weight\n",
      "\t module.features.denseblock4.denselayer16.norm1.bias\n",
      "\t module.features.denseblock4.denselayer16.conv1.weight\n",
      "\t module.features.denseblock4.denselayer16.norm2.weight\n",
      "\t module.features.denseblock4.denselayer16.norm2.bias\n",
      "\t module.features.denseblock4.denselayer16.conv2.weight\n",
      "\t module.features.norm5.weight\n",
      "\t module.features.norm5.bias\n",
      "\t module.classifier.weight\n",
      "\t module.classifier.bias\n",
      "\t module.aux_classifier.weight\n",
      "\t module.aux_classifier.bias\n",
      "FineTuningDensenet121MultiTaskV2_SGDMomentumV7_WeightedMultiLabelLogLoss\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([168])) that is different to the input size (torch.Size([168, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/srv/app/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1104\n",
      "val Loss: 0.0700\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 64m 34s\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.1084\n",
      "val Loss: 0.0698\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 64m 30s\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.1073\n",
      "val Loss: 0.0698\n",
      "Epoch time elapsed: 71m 45s\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1063\n",
      "val Loss: 0.0701\n",
      "Epoch time elapsed: 68m 58s\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1055\n",
      "val Loss: 0.0694\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 67m 4s\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1051\n",
      "val Loss: 0.0696\n",
      "Epoch time elapsed: 84m 15s\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.1037\n",
      "val Loss: 0.0721\n",
      "Epoch time elapsed: 76m 44s\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.1031\n",
      "val Loss: 0.0698\n",
      "Epoch time elapsed: 74m 3s\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.1025\n",
      "val Loss: 0.0692\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 70m 19s\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.1019\n",
      "val Loss: 0.0700\n",
      "Epoch time elapsed: 73m 38s\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.1014\n",
      "val Loss: 0.0692\n",
      "Saving the best model...\n",
      "Epoch time elapsed: 72m 15s\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.1007\n",
      "val Loss: 0.0692\n",
      "Epoch time elapsed: 70m 54s\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0999\n",
      "val Loss: 0.0717\n",
      "Epoch time elapsed: 72m 33s\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0990\n",
      "val Loss: 0.0699\n",
      "Epoch time elapsed: 71m 10s\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0986\n",
      "val Loss: 0.0703\n",
      "Epoch time elapsed: 69m 23s\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0982\n",
      "val Loss: 0.0699\n",
      "Epoch time elapsed: 71m 7s\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0977\n",
      "val Loss: 0.0710\n",
      "Epoch time elapsed: 71m 35s\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0972\n",
      "val Loss: 0.0707\n",
      "Epoch time elapsed: 68m 55s\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0969\n",
      "val Loss: 0.0709\n",
      "Epoch time elapsed: 69m 52s\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_name_list = []\n",
    "metric_list = []\n",
    "\n",
    "for m in MODELS:\n",
    "    for o in OPTIMIZERS:\n",
    "        for l in LOSSES:\n",
    "            \n",
    "            model = getModel(m, NUM_CLASSES)\n",
    "            \n",
    "            optimizer = getOptimizer(o, model)\n",
    "            \n",
    "            criterion = getLossFunction(l)\n",
    "            \n",
    "            model_name = f'{m}_{o}_{l}'\n",
    "            \n",
    "            tensorboard = SummaryWriter(comment = model_name)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model, best_metric = train_model(\n",
    "                model, \n",
    "                model_name, \n",
    "                dataloaders_dict, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                num_epochs=NUM_EPOCH, \n",
    "                is_inception=MODEL_LIST[m]['is_inception'])\n",
    "            \n",
    "            model_name_list.append(model_name)\n",
    "            metric_list.append(best_metric)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(metric_list))  # the x locations for the groups\n",
    "ax.barh(ind, metric_list, width)\n",
    "ax.set_yticks(ind+width/2)\n",
    "ax.set_yticklabels(model_name_list, minor=False)\n",
    "plt.xlabel('Loss')\n",
    "for i, v in enumerate(metric_list):\n",
    "    ax.text(v, i, str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name_list)\n",
    "print(metric_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
